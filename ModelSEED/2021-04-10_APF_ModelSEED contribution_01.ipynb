{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries and JSON files\n",
    "from ftfy import fix_encoding\n",
    "import pandas\n",
    "import numpy\n",
    "import json\n",
    "import re\n",
    "\n",
    "nist = json.load(open('2021-05-06_NIST consolidated.json'))\n",
    "bigg = json.load(open('BiGG model of S. aureus.json'))\n",
    "unknown_compounds = pandas.read_csv(open('2021-05-05_APF_unknown compounds to modelSEED_01.csv'))\n",
    "empty_cell = ['nan', None, numpy.nan, '', ' ', 'NaN', '[]']\n",
    "\n",
    "\n",
    "# creating a complete list of enzymatic reaction names in the BiGG model\n",
    "saureus_enzymes = []\n",
    "for key, value in bigg.items():\n",
    "    #print(key)\n",
    "    if key == 'reactions':\n",
    "        for enzyme in value:\n",
    "            for key2, value2 in enzyme.items():\n",
    "                if key2 == 'name':\n",
    "                    saureus_enzymes.append(value2)\n",
    "                    \n",
    "                    \n",
    "# determining the set of unknown compounds, which originates from previous parsing executions\n",
    "unknown_compounds_list = []\n",
    "for compound in unknown_compounds['Unknown compound names']:\n",
    "    if compound not in unknown_compounds_list:\n",
    "        try:\n",
    "            compound = fix_encoding(compound)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        unknown_compounds_list.append(compound)\n",
    "        \n",
    "#print(unknown_compounds_list)\n",
    "                    \n",
    "\n",
    "# compiling the set of reaction names from the NIST database\n",
    "nist_enzyme_name = []\n",
    "parenthesized_nist_enzymes = []\n",
    "parenthesized_nist_ennzymes_original = []\n",
    "and_conjoined_enzymes = []\n",
    "and_conjoined_enzyme_original = []\n",
    "thermodynamic_enzyme_names = []\n",
    "kinetic_enzymes = []\n",
    "for name, value in nist.items():\n",
    "    nist_enzyme_name.append(name)\n",
    "    for detail, information in value.items():\n",
    "        #print(detail, '\\t', information)\n",
    "        if detail == 'Keq':\n",
    "            for detail2, information2 in information.items():\n",
    "                if detail2 == 'keqs':\n",
    "                    for information3 in information2:\n",
    "                        #print(id, '\\t', information3)\n",
    "                        if information3 not in empty_cell: \n",
    "                            #print('keqs', id)\n",
    "                            if re.search('(\\sand\\s)', name):\n",
    "                                left_enzyme_striped_value = re.sub('(.*and\\s)', '', name)\n",
    "                                right_enzyme_striped_value = re.sub('(\\sand.*)', '', name)\n",
    "                                if left_enzyme_striped_value not in thermodynamic_enzyme_names:\n",
    "                                    thermodynamic_enzyme_names.append(left_enzyme_striped_value)\n",
    "                                if right_enzyme_striped_value not in thermodynamic_enzyme_names:\n",
    "                                    thermodynamic_enzyme_names.append(right_enzyme_striped_value)\n",
    "                                if left_enzyme_striped_value not in and_conjoined_enzymes:\n",
    "                                    and_conjoined_enzymes.append(left_enzyme_striped_value)\n",
    "                                if right_enzyme_striped_value not in and_conjoined_enzymes:\n",
    "                                    and_conjoined_enzymes.append(right_enzyme_striped_value)\n",
    "                                if name not in and_conjoined_enzyme_original:\n",
    "                                    and_conjoined_enzyme_original.append(name)\n",
    "                            else:\n",
    "                                if name not in thermodynamic_enzyme_names:\n",
    "                                    thermodynamic_enzyme_names.append(name)\n",
    "                        else:\n",
    "                            print(information3)\n",
    "\n",
    "        if detail == 'Enthalpy':\n",
    "            for detail2, information2 in information.items():\n",
    "                #print('yay')\n",
    "                #print('information:\\t', detail2, '\\t', information2)\n",
    "                if detail2 == 'enthalpy values':\n",
    "                    #print('yes')\n",
    "                    for information3 in information2:\n",
    "                        if information3 not in empty_cell:\n",
    "                            if re.search('(\\sand\\s)', name):\n",
    "                                left_enzyme_striped_value = re.sub('(.*and\\s)', '', name)\n",
    "                                right_enzyme_striped_value = re.sub('(\\sand.*)', '', name)\n",
    "                                if left_enzyme_striped_value not in thermodynamic_enzyme_names:\n",
    "                                    thermodynamic_enzyme_names.append(left_enzyme_striped_value)\n",
    "                                if right_enzyme_striped_value not in thermodynamic_enzyme_names:\n",
    "                                    thermodynamic_enzyme_names.append(right_enzyme_striped_value)    \n",
    "                                if left_enzyme_striped_value not in and_conjoined_enzymes:\n",
    "                                    and_conjoined_enzymes.append(left_enzyme_striped_value)\n",
    "                                if right_enzyme_striped_value not in and_conjoined_enzymes:\n",
    "                                    and_conjoined_enzymes.append(right_enzyme_striped_value)\n",
    "                                if name not in and_conjoined_enzyme_original:\n",
    "                                    and_conjoined_enzyme_original.append(name)\n",
    "                            else:\n",
    "                                if name not in thermodynamic_enzyme_names:\n",
    "                                    thermodynamic_enzyme_names.append(name)\n",
    "                        else:\n",
    "                             print(information3)   \n",
    "     \n",
    "        if detail == 'Km':\n",
    "            for detail2, information2 in information.items():\n",
    "                #print('yay')\n",
    "                #print('information:\\t', detail2, '\\t', information2)\n",
    "                if detail2 == 'km values':\n",
    "                    #print('yes')\n",
    "                    for information3 in information2:\n",
    "                        if information3 not in empty_cell:\n",
    "                            if name not in kinetic_enzymes:\n",
    "                                kinetic_enzymes.append(name)\n",
    "                                #print('kinetics', name)\n",
    "                        else:\n",
    "                             print(information3)           \n",
    "                                \n",
    "        \n",
    "        if re.search('(\\s\\(.*\\))', name):\n",
    "            striped_value = re.sub('(\\s\\(.*\\))', '', name)\n",
    "            #print(striped_value)\n",
    "            parenthesized_nist_enzymes.append(striped_value)\n",
    "            parenthesized_nist_ennzymes_original.append(name)\n",
    "            \n",
    "                \n",
    "'''for enzyme in and_conjoined_enzyme_original:\n",
    "    index = and_conjoined_enzyme_original.index(enzyme)\n",
    "    for entry in nist[enzyme]['Keq']['keqs']:\n",
    "        if entry not in empty_cell and and_conjoined_enzymes[index] not in thermodynamic_enzyme_names:\n",
    "            thermodynamic_enzyme_names.append(enzyme)\n",
    "    for entry in nist[enzyme]['Enthalpy']['enthalpy values']:\n",
    "        if entry not in empty_cell and and_conjoined_enzymes[index] not in thermodynamic_enzyme_names:\n",
    "            thermodynamic_enzyme_names.append(enzyme)'''\n",
    "            \n",
    "                \n",
    "'''print('separated enzymes: %s\\n' %(len(and_conjoined_enzymes)), set(and_conjoined_enzymes))   \n",
    "print('\\noriginal enzymes: %s\\n' %(len(and_conjoined_enzyme_original)), set(and_conjoined_enzyme_original))     '''       \n",
    "\n",
    "'''print(parenthesized_nist_enzymes)\n",
    "nist_enzyme_name += and_conjoined_enzymes\n",
    "thermodynamic_enzyme_names.append('test')'''\n",
    "        \n",
    "    \n",
    "# comparing the NIST and BiGG databases \n",
    "represented_enzymes = []\n",
    "represented_nist_enzymes = []\n",
    "for enzyme in saureus_enzymes:\n",
    "    for enzyme2 in thermodynamic_enzyme_names:\n",
    "        if enzyme.lower() == enzyme2.lower():\n",
    "            represented_enzymes.append(enzyme)\n",
    "            represented_nist_enzymes.append(enzyme2)\n",
    "    \n",
    "    \n",
    "'''    for enzyme2 in nist_enzyme_name:\n",
    "        if enzyme.lower() == enzyme2.lower(): \n",
    "            if enzyme not in represented_enzymes:\n",
    "                represented_enzymes.append(enzyme)\n",
    "                represented_nist_enzymes.append(enzyme2)\n",
    "    for enzyme3 in parenthesized_nist_enzymes:\n",
    "        if re.search(enzyme3, enzyme):\n",
    "            #print(enzyme)\n",
    "            if enzyme not in represented_enzymes:\n",
    "                index = parenthesized_nist_enzymes.index(enzyme3)\n",
    "                represented_enzymes.append(enzyme)\n",
    "                represented_nist_enzymes.append(parenthesized_nist_ennzymes_original[index])\n",
    "    for enzyme3 in and_conjoined_enzymes:\n",
    "        if re.search(enzyme3, enzyme):\n",
    "            #print(enzyme)\n",
    "            if enzyme not in represented_enzymes:\n",
    "                print(enzyme, '\\t', enzyme3)\n",
    "                index = and_conjoined_enzymes.index(enzyme3)\n",
    "                represented_enzymes.append(enzyme)\n",
    "                represented_nist_enzymes.append(and_conjoined_enzyme_original[index])'''\n",
    "                \n",
    "                \n",
    "'''unexpressed_enzymes = (set(nist_enzyme_name) - set(represented_nist_enzymes))\n",
    "unexpressed_nist_enzymes_counted = len(nist_enzyme_name) - len(represented_enzymes)\n",
    "not_thermodynamic_enzymes = set(nist_enzyme_name) - set(thermodynamic_enzyme_names)\n",
    "    \n",
    "print('\\nTotal BiGG enzymes:', len(saureus_enzymes))\n",
    "print('\\nNot thermodynamic enzymes:', len(not_thermodynamic_enzymes))\n",
    "print('\\nTotal unexpressed NIST enzymes:', unexpressed_nist_enzymes_counted)\n",
    "print('\\nUnexpressed enzymes from the NIST database: %s\\n' %(len(unexpressed_enzymes)), unexpressed_enzymes)\n",
    "print('\\nThermodynamic enzymes in the NIST database: %s\\n' %(len(thermodynamic_enzyme_names)), \n",
    "      thermodynamic_enzyme_names)\n",
    "print('\\nS. aureus represented by the NIST database: %s\\n' %(len(represented_enzymes)), represented_enzymes)\n",
    "print('\\nKinetics in the NIST database: %s\\n' %(len(kinetic_enzymes)), kinetic_enzymes)'''\n",
    "\n",
    "'''thermodynamic_dictionary = {}\n",
    "for enzyme in thermodynamic_enzyme_names:\n",
    "    thermodynamic_dictionary[enzyme] = '''\n",
    "\n",
    "\n",
    "# export the parsed reaction names to a CSV file\n",
    "'''dataframe = pandas.DataFrame.from_dict({'separated enzymes':thermodynamic_enzyme_names,\n",
    "                                     'conjoined enzymes':and_conjoined_enzyme_original},\n",
    "                            orient = 'index')\n",
    "dataframe = dataframe.transpose()\n",
    "dataframe.to_csv('2021-04-29_APF_thermodynamically described enzymes_01.csv')'''\n",
    "\n",
    "\n",
    "\n",
    "# determine the set of metabolites in the thermodynamically described reactions\n",
    "described_compounds = []\n",
    "absent_compounds_from_modelseed = {}\n",
    "for enzyme in nist:\n",
    "    for enzyme2 in thermodynamic_enzyme_names:\n",
    "        printed_enzyme = 'no'\n",
    "        if re.search('(-)', enzyme2):\n",
    "            enzyme2 = re.sub('(-)', '(\\-)', enzyme2)\n",
    "        if re.search(enzyme2, enzyme):\n",
    "            #print(enzyme,'\\n', enzyme2)\n",
    "            reactants_list = []\n",
    "            products_list = []\n",
    "            for reaction in nist[enzyme]['reaction']:\n",
    "                #print(reaction)\n",
    "                reaction = fix_encoding(reaction)\n",
    "                #print(reaction)\n",
    "                if re.search('(=)', reaction):\n",
    "                    reaction_split = reaction.split('=')\n",
    "                    #print('reaction:\\t', reaction)\n",
    "                    reactants = reaction_split[0]\n",
    "                    products = reaction_split[1] \n",
    "                    #print('reactants:\\t', reactants)\n",
    "                    #print('products:\\t', products)\n",
    "                    reactants_list = reactants.split(' + ')\n",
    "                    products_list = products.split(' + ')\n",
    "                    #print('reactants list:\\t', reactants_list)\n",
    "                    #print('products list:\\t', products_list)\n",
    "                    for element in reactants_list:\n",
    "                        #print(element)\n",
    "                        element = element.strip()\n",
    "                        element = re.sub('(\\(aq\\)|\\(l\\)|\\(sln\\)|\\(liq\\))', '', element)\n",
    "                        element = re.sub('(\\d\\s|\\d\\/\\d\\s)', '', element)\n",
    "                        if element not in described_compounds:\n",
    "                            #print(element)\n",
    "                            described_compounds.append(element)\n",
    "                        if element in unknown_compounds_list:\n",
    "                            absent_compounds_from_modelseed[element] = {'Enzyme': enzyme,\n",
    "                                                                        'Reaction': reaction,\n",
    "                                                                        'synonym': ''}\n",
    "                            \n",
    "                            printed_enzyme = 'yes'\n",
    "                            \n",
    "                    for element in products_list:\n",
    "                        #print(element)\n",
    "                        element = element.strip()\n",
    "                        element = re.sub('(\\(aq\\)|\\(l\\)|\\(sln\\)|\\(liq\\))', '', element)\n",
    "                        element = re.sub('(\\d\\s|\\d\\/\\d\\s)', '', element)\n",
    "                        if element not in described_compounds:\n",
    "                            print(reaction)\n",
    "                            print(element)\n",
    "                            described_compounds.append(element)\n",
    "                        if element in unknown_compounds_list and printed_enzyme == 'no' :\n",
    "                            absent_compounds_from_modelseed[element] = {'Enzyme': enzyme,\n",
    "                                                                        'Reaction': reaction,\n",
    "                                                                        'synonym': ''}\n",
    "                            \n",
    "                            \n",
    "                else:\n",
    "                    print('abnormal reaction:\\t', reaction)\n",
    "\n",
    "'''with open('2021-05-09_APF_absent NIST compounds from modelSEED_01.json', 'w') as output:\n",
    "    json.dump(absent_compounds_from_modelseed, output, indent = 4)'''\n",
    "                    \n",
    "                    \n",
    "\n",
    "'''export_comopunds_yes_no = {}\n",
    "for compound in described_compounds:\n",
    "    export_comopunds_yes_no[compound] = {'logical name': 'yes',\n",
    "                                        'present in KEGG': ''}\n",
    "\n",
    "with open('2021-04-29_APF_nist thermodynamically described compounds for ModelSEED_02.json', 'w') as output:\n",
    "    json.dump(export_comopunds_yes_no, output, indent = 4)'''\n",
    "\n",
    "\n",
    "# create the clean set of reactions for the ModelSEED repository code\n",
    "'''rearranged_reactions_for_modelseed = []\n",
    "to_be_rearranged = []\n",
    "export_reactions_for_modelseed = {}\n",
    "for enzyme in nist:\n",
    "    for enzyme2 in thermodynamic_enzyme_names:\n",
    "        if re.search('(-)', enzyme2):\n",
    "            enzyme2 = re.sub('(\\-)', '\\-', enzyme2)\n",
    "        if re.search(enzyme2, enzyme):\n",
    "            for reaction in nist[enzyme]['reaction']:\n",
    "                reaction = fix_encoding(reaction)\n",
    "                #print(reaction)\n",
    "                if reaction not in to_be_rearranged:\n",
    "                    to_be_rearranged.append(reaction)\n",
    "                    #print(reaction)\n",
    "                    \n",
    "                    # replace the phase identifiers\n",
    "                    if re.search('(\\(aq\\)|\\(l\\)|\\(sln\\)|\\(liq\\))', reaction):\n",
    "                        reaction = re.sub('(\\(aq\\)|\\(l\\)|\\(sln\\)|\\(liq\\))', '', reaction)\n",
    "                    #print(reaction)\n",
    "                    \n",
    "                    # arrange the reaction equilibrium arrow and stoichiometric coefficients for ModelSEED\n",
    "                    if re.search('(\\s?=\\s?)', reaction):\n",
    "                        reaction = re.sub('(\\s?=\\s?)', ' <=> ', reaction)\n",
    "                        \n",
    "                    if re.search('((?<!\\w)\\d\\s|\\d\\/\\d\\s)', reaction):\n",
    "                        reaction = re.sub('((?<!\\w)\\d\\s|\\d\\/\\d\\s)', r'(\\1) ', reaction)\n",
    "                        reaction = re.sub('(?<=\\d)(\\s)(?=\\))', '', reaction)\n",
    "                    else:\n",
    "                        reaction = re.sub('(?<=\\+)(\\s)', ' (1) ', reaction)\n",
    "                        reaction = re.sub('(?<=>)(\\s)', ' (1) ', reaction)\n",
    "                        \n",
    "                    if reaction[0] == ' ':\n",
    "                        reaction = re.sub('\\s', '(1) ', reaction, 1)\n",
    "                    else:\n",
    "                        reaction = '(1) ' + reaction\n",
    "                        \n",
    "                    reaction = re.sub('(?<=\\w)(\\s)(?=<|\\+)', '[0] ', reaction)\n",
    "                    reaction += '[0]'\n",
    "                    #print(reaction)\n",
    "                    if reaction not in rearranged_reactions_for_modelseed:\n",
    "                        enzyme2 = re.sub(r'(\\\\)', '', enzyme2)\n",
    "                        export_reactions_for_modelseed[enzyme2] = {'reaction expression':reaction,\n",
    "                                                                   'yes_no':''}\n",
    "                        rearranged_reactions_for_modelseed.append(reaction)\n",
    "                    else:\n",
    "                        print('repeated reactions:\\t', reaction)\n",
    "\n",
    "\n",
    "print('\\nFinal reactions:')\n",
    "for reaction in rearranged_reactions_for_modelseed:\n",
    "    print(reaction)\n",
    "    \n",
    "with open('2021-05-09_APF_nist thermodynamically described reactions for ModelSEED_01.json', 'w') as output:\n",
    "    json.dump(export_reactions_for_modelseed, output, indent = 4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "wckb = json.load(open('2021-03-25_APF_WCKB reactions + references.json'))\n",
    "wckb_metabolites = json.load(open('2021-03-17_APF_Karr et al. metabolite data.json'))\n",
    "\n",
    "empty_cells = ['NaN', None, numpy.nan, '', ' ', 'null', 'None', 'nan', '[None]', '[\\'None\\']']    \n",
    "\n",
    "# determine the set of thermodynamically described reactions from the WCKB downloaded json data\n",
    "thermodynamically_described_enzymes_wckb = []\n",
    "wckb_enzymes = []\n",
    "wckb_keqs = []\n",
    "wckb_kinetics = []\n",
    "wckb_gibbs = []\n",
    "for enzyme, value in wckb.items():\n",
    "    if enzyme not in wckb_enzymes:\n",
    "        #print(enzyme)\n",
    "        wckb_enzymes.append(enzyme)\n",
    "        for keq in value['keq']:\n",
    "            if keq not in empty_cells and enzyme not in wckb_gibbs:\n",
    "                thermodynamically_described_enzymes_wckb.append(enzyme)\n",
    "                wckb_keqs.append(enzyme)\n",
    "        for gibbs in value['Gibbs free energy']:\n",
    "            if gibbs not in empty_cells and enzyme not in wckb_gibbs:\n",
    "                thermodynamically_described_enzymes_wckb.append(enzyme)\n",
    "                wckb_gibbs.append(enzyme)\n",
    "        for forward_kinetics in value['forward kinetics']:\n",
    "            if forward_kinetics not in empty_cells and enzyme not in wckb_gibbs:\n",
    "                wckb_kinetics.append(enzyme)\n",
    "        for backward_kinetics in value['backward kinetics']:\n",
    "            if backward_kinetics not in empty_cells and enzyme not in wckb_gibbs:\n",
    "                wckb_kinetics.append(enzyme)\n",
    "                \n",
    "print('\\n\\nWCKB enzymes:\\t\\t', len(wckb_enzymes)) \n",
    "print('Thermodynamically described enzymes: ', len(thermodynamically_described_enzymes)) \n",
    "print('WCKB Keqs:\\t\\t', len(wckb_keqs))   \n",
    "print('WCKB Kinetics:\\t\\t', len(wckb_kinetics))\n",
    "print('WCKB gibbs:\\t\\t', len(wckb_gibbs))     \n",
    "                            \n",
    "thermodynamically_described_enzymes = set(wckb_gibbs).union(set(wckb_keqs))\n",
    "wckb_reactions = []\n",
    "export_reactions_wckb_for_modelseed = {}\n",
    "for enzyme in thermodynamically_described_enzymes:\n",
    "    for entry in wckb[enzyme]['stoichiometry']:\n",
    "        compound_loop = 0\n",
    "        product_loop = 0\n",
    "        for molecule in entry:\n",
    "            if molecule['compartment'] == 'c':\n",
    "                compartment_value = 0\n",
    "            elif molecule['compartment'] == 'e':\n",
    "                compartment_value = 1\n",
    "            elif molecule['compartment'] == 'm':\n",
    "                compartment_value = 2\n",
    "                \n",
    "            if compound_loop == 0:\n",
    "                reaction_string = '(%s) %s[%d]'  %(abs(int(float(molecule['coefficient']))), molecule['molecule'], compartment_value)\n",
    "                compound_loop += 1\n",
    "            elif product_loop == 0 and float(molecule['coefficient']) > 0: \n",
    "                reaction_string += ' <=> (%s) %s[%d]'  %(int(float(molecule['coefficient'])), molecule['molecule'], compartment_value)            \n",
    "                product_loop += 1\n",
    "            else:\n",
    "                reaction_string += ' + (%s) %s[%d]'  %(abs(int(float(molecule['coefficient']))), molecule['molecule'], compartment_value)\n",
    "        print(reaction_string)\n",
    "        wckb_reactions.append(reaction_string)       \n",
    "        export_reactions_wckb_for_modelseed[enzyme] = {'reaction expression':reaction_string,\n",
    "                                                       'yes_no':''}\n",
    "                    \n",
    "          \n",
    "                \n",
    "with open('2021-04-29_APF_wckb thermodynamically described reactions for ModelSEED_01.json', 'w') as output:\n",
    "    json.dump(export_reactions_wckb_for_modelseed, output, indent = 4)\n",
    "    \n",
    "    \n",
    "# determine the set of thermodynamically described compounds from the aforementioned reactions\n",
    "'''described_compounds = []\n",
    "for enzyme in thermodynamically_described_enzymes:\n",
    "    for entry in wckb[enzyme]['stoichiometry']:\n",
    "        for molecule in entry:\n",
    "            if molecule['molecule'] not in described_compounds:\n",
    "                described_compounds.append(molecule['molecule'])\n",
    "            try:\n",
    "                proper_molecule = wckb_metabolites[molecule['molecule']]['Name']\n",
    "                #print(molecule['molecule'])\n",
    "                #print(proper_molecule)\n",
    "            except:\n",
    "                print('abbreviation-only compound:\\t', molecule['molecule'])\n",
    "                proper_molecule = molecule['molecule']\n",
    "                proper_molecule = re.sub('(MG_287_MONOMER.)', '', proper_molecule)\n",
    "                proper_molecule = re.sub('(MG_287_MONOMER|NA)', 'unknown', proper_molecule)\n",
    "            if proper_molecule not in described_compounds:\n",
    "                described_compounds.append(proper_molecule)\n",
    "            \n",
    "print('\\n\\nThermodynamically described compounds: ', len(described_compounds))\n",
    "export_wckb_compounds_yes_no = {}\n",
    "for compound in described_compounds:\n",
    "    export_wckb_compounds_yes_no[compound] = ''\n",
    "    print(compound)\n",
    "    \n",
    "with open('2021-04-29_APF_wckb thermodynamically described compounds for ModelSEED_01.json', 'w') as output:\n",
    "    json.dump(export_wckb_compounds_yes_no, output, indent = 4)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "wckb = json.load(open('2021-04-29_APF_nist thermodynamically described compounds for ModelSEED_02.json'))\n",
    "nist = json.load(open('2021-04-29_APF_wckb thermodynamically described compounds for ModelSEED_01.json'))\n",
    "wckb_2 = json.load(open('2021-04-29_APF_wckb thermodynamically described reactions for ModelSEED_01.json'))\n",
    "nist_2 = json.load(open('2021-04-29_APF_nist thermodynamically described reactions for ModelSEED_02.json'))\n",
    "    \n",
    "    \n",
    "# combine the thermodynamically described compounds from the NIST and WCKB sources\n",
    "'''export_union_compounds = {}\n",
    "union_compounds = []\n",
    "excluded_compounds = []\n",
    "nist_compounds = []\n",
    "wckb_compounds = []\n",
    "for compound in nist:\n",
    "    nist_compounds.append(compound)\n",
    "    for compound2 in wckb:\n",
    "        wckb_compounds.append(compound2)\n",
    "        if compound.lower() == compound2.lower():\n",
    "            if compound not in union_compounds:\n",
    "                union_compounds.append(compound)\n",
    "                export_union_compounds[compound] = \"\"\n",
    "\n",
    "print('union compounds:\\t', len(union_compounds))\n",
    "for compound in union_compounds:\n",
    "    print(compound)\n",
    "    \n",
    "complete_compounds_set = set(nist_compounds).union(set(wckb_compounds))\n",
    "sorted_set_compounds = sorted(complete_compounds_set)\n",
    "complete_thermodynamic_compounds = {}\n",
    "print('\\n\\ncomplete compounds set:\\t', len(complete_compounds_set))\n",
    "for compound in sorted_set_compounds:\n",
    "    complete_thermodynamic_compounds[compound] = ''\n",
    "    print(compound)\n",
    "    \n",
    "    \n",
    "with open('2021-04-29_APF_complete thermodynamically described compounds for KEGG_01.json', 'w') as output:\n",
    "    json.dump(complete_thermodynamic_compounds, output, indent = 4)\n",
    "    \n",
    "with open('2021-04-30_APF_ModelSEED formatted compounds.tsv', 'w') as output:\n",
    "    #output.write(\"id\" + \"name\" + \"abbreviation\" + \"aliases\" + \"formula\" + \"mass\" + \"charge\" + \"deltag\" + \"deltagerr\" + \"pka\" + \"pkb\" + \"inchikey\" + \"smiles\" + \"is_cofactor\" + \"is_core\" + \"is_obsolete\" + \"abstract_compound\" + \"comprised_of\" + \"linked_compound\" + \"notes\" + \"source\" + '\\n')\n",
    "    output.write('\\t'.join(['NAMES','ID', '\\n']))\n",
    "    for compound in complete_thermodynamic_compounds:\n",
    "        output.write('\\t'.join([compound, ]) + '\\n')'''\n",
    "    \n",
    "    \n",
    "# combine the thermodynamically described reactions from the NIST and WCKB sources\n",
    "'''export_union_reactions = {}\n",
    "union_reactions = []\n",
    "nist_reactions = []\n",
    "wckb_reactions = []\n",
    "for reaction in nist_2:\n",
    "    nist_reactions.append(reaction)\n",
    "    for reaction2 in wckb_2:\n",
    "        wckb_reactions.append(reaction2)\n",
    "        if reaction.lower() == reaction2.lower():\n",
    "            if reaction not in union_reactions:\n",
    "                union_reactions.append(reaction)\n",
    "                export_union_reactions[reaction] =''\n",
    "                \n",
    "print('union reactions:\\t', len(union_reactions))\n",
    "for reaction in union_reactions:\n",
    "    print(reaction)\n",
    "    \n",
    "complete_reactions_set = set(nist_reactions).union(set(wckb_reactions))\n",
    "sorted_set_reactions = sorted(complete_reactions_set)\n",
    "complete_thermodynamic_reactions = {}\n",
    "print('\\n\\ncomplete compounds set:\\t', len(sorted_set_reactions))\n",
    "for reaction in sorted_set_reactions:\n",
    "    #reaction = re.sub('(\\))', '\\)', reaction)\n",
    "    #print(reaction)\n",
    "    try:\n",
    "        complete_thermodynamic_reactions[reaction] = {'reaction expression':nist_2[reaction]['reaction expression'],\n",
    "                                                      'yes_no':''}\n",
    "    except:\n",
    "        complete_thermodynamic_reactions[reaction] = {'reaction expression':wckb_2[reaction]['reaction expression'],\n",
    "                                                      'yes_no':''}\n",
    "    \n",
    "    \n",
    "with open('2021-04-30_APF_complete thermodynamically described reactions for KEGG_01.json', 'w') as output:\n",
    "    json.dump(complete_thermodynamic_reactions, output, indent = 4)\n",
    "    \n",
    "with open('2021-04-30_APF_ModelSEED formatted reactions.tsv', 'w') as output:\n",
    "    output.write('\\t'.join(['NAMES','reaction', '\\n']))\n",
    "    for reaction in complete_thermodynamic_reactions:\n",
    "        output.write('\\t'.join([reaction, \n",
    "                                complete_thermodynamic_reactions[reaction]['reaction expression']]) + '\\n')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ftfy import fix_encoding\n",
    "import pandas\n",
    "\n",
    "processing_data = json.load(open('2021-04-29_APF_nist thermodynamically described compounds for ModelSEED_01.json'))\n",
    "\n",
    "illogically_named_enzymes = []\n",
    "for compound in processing_data:\n",
    "    #print(compound, '\\n', processing_data[compound])\n",
    "    if processing_data[compound]['logical name'] == 'no':\n",
    "        compound = fix_encoding(compound)\n",
    "        illogically_named_enzymes.append(compound)\n",
    "        print(compound)\n",
    "        \n",
    "dataframe = pandas.DataFrame(data = {'Unknown compound names':illogically_named_enzymes})\n",
    "\n",
    "print('\\nTotal described compounds: ', len(illogically_named_enzymes))\n",
    "\n",
    "\n",
    "with open('2021-05-05_APF_unknown compounds to modelSEED_01.csv', 'w', encoding=\"utf-8\") as output:\n",
    "    dataframe.to_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries and the JSON data files        \n",
    "import pandas\n",
    "import numpy\n",
    "import json\n",
    "import re\n",
    "\n",
    "nist = json.load(open('2021-03-29_APF_NIST consolidated_01.json'))\n",
    "wckb_json = json.load(open('2021-03-25_APF_WCKB reactions + references.json'))\n",
    "wckb_metabolites = json.load(open('2021-03-17_APF_Karr et al. metabolite data.json'))\n",
    "empty_cells = ['NaN', None, numpy.nan, '', ' ', 'null', 'None', 'nan', '[None]', '[\\'None\\']']    \n",
    "\n",
    "    \n",
    "# examine the data from the scraped NIST database\n",
    "nist_enzymes = []\n",
    "nist_keqs = []\n",
    "nist_kms = []\n",
    "nist_enthalpies = []\n",
    "for enzyme, value in nist.items():\n",
    "    if enzyme not in nist_enzymes:\n",
    "        #print(enzyme)\n",
    "        nist_enzymes.append(enzyme)\n",
    "        #print(value['Keq'])\n",
    "        for key1, values in value['Keq'].items():\n",
    "            if key1 == 'keqs':      \n",
    "                #print(key1, values)\n",
    "                for key in values:\n",
    "                    if key not in empty_cells and enzyme not in nist_keqs:\n",
    "                        nist_keqs.append(enzyme)\n",
    "        for key1, values in value['Km'].items():\n",
    "            if key1 == 'km values':      \n",
    "                #print(key1, values)\n",
    "                for key in values:\n",
    "                    if key not in empty_cells and enzyme not in nist_kms:\n",
    "                        nist_kms.append(enzyme)\n",
    "        for key1, values in value['Enthalpy'].items():\n",
    "            if key1 == 'enthalpy values':      \n",
    "                #print(key1, values)\n",
    "                for key in values:\n",
    "                    if key not in empty_cells and enzyme not in nist_enthalpies:\n",
    "                        nist_enthalpies.append(enzyme)\n",
    "\n",
    "                            \n",
    "                            \n",
    "print('NIST enzymes:\\t\\t', len(nist_enzymes))                      \n",
    "print('NIST Keqs:\\t\\t', len(nist_keqs))   \n",
    "print('NIST Kms:\\t\\t', len(nist_kms))\n",
    "print('NIST enthalpies:\\t', len(nist_enthalpies))\n",
    "\n",
    "\n",
    "# examine the data from the downloaded WCKB database\n",
    "wckb_enzymes = []\n",
    "wckb_keqs = []\n",
    "wckb_kinetics = []\n",
    "wckb_gibbs = []\n",
    "for enzyme, value in wckb_json.items():\n",
    "    if enzyme not in wckb_enzymes:\n",
    "        #print(enzyme)\n",
    "        wckb_enzymes.append(enzyme)\n",
    "        for keq in value['keq']:\n",
    "            if keq not in empty_cells:\n",
    "                wckb_keqs.append(enzyme)\n",
    "        for gibbs in value['Gibbs free energy']:\n",
    "            if gibbs not in empty_cells and enzyme not in wckb_gibbs:\n",
    "                wckb_gibbs.append(enzyme)\n",
    "        for forward_kinetics in value['forward kinetics']:\n",
    "            if forward_kinetics not in empty_cells:\n",
    "                if enzyme not in wckb_kinetics:\n",
    "                    wckb_kinetics.append(enzyme)\n",
    "        for backward_kinetics in value['backward kinetics']:\n",
    "            if backward_kinetics not in empty_cells:\n",
    "                if enzyme not in wckb_kinetics:\n",
    "                    wckb_kinetics.append(enzyme)\n",
    "                            \n",
    "print('\\n\\nWCKB enzymes:\\t\\t', len(wckb_enzymes))                      \n",
    "print('WCKB Keqs:\\t\\t', len(wckb_keqs))   \n",
    "print('WCKB Kinetics:\\t\\t', len(wckb_kinetics))\n",
    "print('WCKB gibbs:\\t\\t', len(wckb_gibbs))\n",
    "\n",
    "\n",
    "# contrast the wckb and nist datasets\n",
    "conjoined_enzymes = []\n",
    "union_enzymes = {}\n",
    "thermodynamically_described_enzymes = []\n",
    "thermodynamically_undescribed_enzymes = []\n",
    "thermodynamically_described_enzymes_wckb = []\n",
    "thermodynamically_described_enzymes_nist = []\n",
    "for enzyme in wckb_enzymes:\n",
    "    union_enzymes[enzyme.lower()] = {'source 1':'Whole cell'}\n",
    "    for element in wckb_json[enzyme]['Gibbs free energy']:\n",
    "        for element2 in wckb_json[enzyme]['keq']:\n",
    "            if (element or element2) not in empty_cells:\n",
    "                #print(wckb_json[enzyme]['keq'], '\\n', wckb_json[enzyme]['Gibbs free energy'])\n",
    "                thermodynamically_described_enzymes.append(enzyme.lower())\n",
    "                thermodynamically_described_enzymes_wckb.append(enzyme)\n",
    "            else:\n",
    "                thermodynamically_undescribed_enzymes.append(enzyme.lower())\n",
    "        \n",
    "for enzyme2 in nist_enzymes:\n",
    "    if enzyme2.lower() in union_enzymes.keys():\n",
    "        union_enzymes[enzyme2.lower()]['source 2'] = 'NIST'\n",
    "    else:\n",
    "        union_enzymes[enzyme2.lower()] = {'source 1':'NIST'}\n",
    "    if enzyme2.lower() not in thermodynamically_described_enzymes:\n",
    "        thermodynamically_described_enzymes.append(enzyme2.lower())\n",
    "   \n",
    "    thermodynamically_described_enzymes_nist.append(enzyme2)\n",
    "    \n",
    "#print(enzyme2, '\\t', union_enzymes[enzyme2.lower()])\n",
    "        \n",
    "described_compounds = []\n",
    "for enzyme in thermodynamically_described_enzymes_wckb:\n",
    "    if enzyme.lower() in thermodynamically_described_enzymes:\n",
    "        for entry in wckb_json[enzyme]['stoichiometry']:\n",
    "            for molecule in entry:\n",
    "                try:\n",
    "                    proper_molecule = wckb_metabolites[molecule['molecule']]['Name']\n",
    "                    #print(molecule['molecule'])\n",
    "                    #print(proper_molecule)\n",
    "                except:\n",
    "                    print('ignored compound:\\t', molecule['molecule'])\n",
    "                    #proper_molecule = molecule['molecule']\n",
    "                if proper_molecule not in described_compounds:\n",
    "                    described_compounds.append(proper_molecule)\n",
    "        \n",
    "for enzyme in thermodynamically_described_enzymes_nist:\n",
    "    reactants_list = []\n",
    "    products_list = []\n",
    "    for reaction in nist[enzyme]['reaction']:\n",
    "        #print('original reaction:\\t', reaction) \n",
    "        if re.search('(=)', reaction):\n",
    "            reaction = reaction.split('=')\n",
    "            #print('reaction:\\t', reaction)\n",
    "            reactants = reaction[0]\n",
    "            products = reaction[1] \n",
    "            #print('reactants:\\t', reactants)\n",
    "            #print('products:\\t', products)\n",
    "            reactants_list = reactants.split('+')\n",
    "            products_list = products.split('+')\n",
    "            #print('reactants list:\\t', reactants_list)\n",
    "            #print('products list:\\t', products_list)\n",
    "            for element in reactants_list:\n",
    "                #print(element)\n",
    "                element.strip()\n",
    "                if element not in described_compounds:\n",
    "                    described_compounds.append(element)\n",
    "            for element in products_list:\n",
    "                #print(element)\n",
    "                element.strip()\n",
    "                if element not in described_compounds:\n",
    "                    described_compounds.append(element)\n",
    "        \n",
    "        \n",
    "# contributing total compound information     \n",
    "'''compound_information = {}    \n",
    "for compound in described_compounds:\n",
    "    #print(compound\n",
    "    compound_information[compound] = { \"id\":\"\",\n",
    "                                      \"abbreviation\":\"\",\n",
    "                                      \"aliases\":\"\",\n",
    "                                      \"formula\":\"\",\n",
    "                                      \"mass\":'',\n",
    "                                      \"charge\":'',\n",
    "                                      \"deltag\":'',\n",
    "                                      \"deltagerr\":'',\n",
    "                                      \"pka\":\"\",\n",
    "                                      \"pkb\":\"\",\n",
    "                                      \"inchikey\":\"\",\n",
    "                                      \"smiles\":\"\",\n",
    "                                      \"is_cofactor\":'',\n",
    "                                      \"is_core\":'',\n",
    "                                      \"is_obsolete\":'',\n",
    "                                      \"abstract_compound\":\"\",\n",
    "                                      \"comprised_of\":\"\",\n",
    "                                      \"linked_compound\":\"\",\n",
    "                                      \"notes\":[],\n",
    "                                      \"source\":\"\" }\n",
    "    compound_information[compound]['']'''\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "'''for enzyme in wckb_enzymes:\n",
    "    for enzyme2 in nist_enzymes:\n",
    "        #print(enzyme)\n",
    "        if str(enzyme).lower() == str(enzyme2).lower():\n",
    "            if enzyme not in conjoined_enzymes:\n",
    "                conjoined_enzymes.append(enzyme)\n",
    "print('\\nenzyme balance:\\t', len(wckb_enzymes) + len(nist_enzymes) == len(conjoined_enzymes) + len(union_enzymes), '\\n')                \n",
    "print('Conjoined NIST and WCKB enzymes:', len(conjoined_enzymes), '\\n')\n",
    "for enzyme in conjoined_enzymes:\n",
    "    print(enzyme)\n",
    "print('Union of enzymes:\\t', len(union_enzymes), '\\n')\n",
    "for enzyme in union_enzymes:\n",
    "    print(enzyme)'''\n",
    "\n",
    "\n",
    "\n",
    "print('Quantity of thermodynamically described enzymes:\\t', len(thermodynamically_described_enzymes))            \n",
    "print('Quantity of thermodynamically undescribed enzymes:\\t', len(thermodynamically_undescribed_enzymes))        \n",
    "\n",
    "\n",
    "\n",
    "with open('2021-04-26_APF_ModelSEED formatted compounds.tsv', 'w') as output:\n",
    "    #output.write(\"id\" + \"name\" + \"abbreviation\" + \"aliases\" + \"formula\" + \"mass\" + \"charge\" + \"deltag\" + \"deltagerr\" + \"pka\" + \"pkb\" + \"inchikey\" + \"smiles\" + \"is_cofactor\" + \"is_core\" + \"is_obsolete\" + \"abstract_compound\" + \"comprised_of\" + \"linked_compound\" + \"notes\" + \"source\" + '\\n')\n",
    "    output.write('\\t'.join(['NAMES','ID', '\\n']))\n",
    "    number = 0\n",
    "    for enzyme in described_compounds:\n",
    "        output.write('\\t'.join([enzyme, '%s'%(number)]) + '\\n')\n",
    "        number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and the text files \n",
    "import pandas\n",
    "import json\n",
    "\n",
    "ids = pandas.read_csv('Unique_ModelSEED_Compound_Aliases.txt', sep = '\\t')\n",
    "names = pandas.read_csv('Unique_ModelSEED_Compound_Names.txt', sep = '\\t')\n",
    "compounds = json.load(open('2021-04-29_APF_nist thermodynamically described compounds for ModelSEED_02.json'))\n",
    "\n",
    "#display(ids.head(5))\n",
    "#display(names.head(5))\n",
    "\n",
    "# parse the compounds through the ModelSEED text files\n",
    "compound_information = {}\n",
    "repeated_compounds = []\n",
    "for compound in compounds:\n",
    "    for index, modelseed_name in names.iterrows():\n",
    "        if str(compound).lower() == str(modelseed_name['External ID']).lower():\n",
    "            if modelseed_name['ModelSEED ID'] not in compound_information.keys():\n",
    "                for index2, id in ids.iterrows():\n",
    "                    if id['ModelSEED ID'] == modelseed_name['ModelSEED ID']:\n",
    "                        if id['Source'] == 'KEGG':\n",
    "                            print(modelseed_name)\n",
    "                            #print(modelseed_name['ModelSEED ID'])\n",
    "                            #print(id['External ID'])\n",
    "                            compound_information[modelseed_name['ModelSEED ID']] = {'ModelSEED name': modelseed_name['External ID'],\n",
    "                                                                                    'KEGG ID':id['External ID']}\n",
    "                            #print(compound_information.keys())\n",
    "\n",
    "            else:\n",
    "                repeated_compounds.append(modelseed_name)\n",
    "\n",
    "compounds_list = []\n",
    "for compound in compound_information.keys():\n",
    "    compounds_list.append(compound)\n",
    "    \n",
    "print('Identified compounds: ', len(compounds_list))\n",
    "print('repeated compounds: ', len(repeated_compounds))\n",
    "\n",
    "with open('2021-05-03_APF_KEGG and ModelSEED_IDs_01', 'w') as output:\n",
    "    json.dump(compound_information, output, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and the text files \n",
    "import pandas\n",
    "import json\n",
    "\n",
    "ids = pandas.read_csv('Unique_ModelSEED_Compound_Aliases.txt', sep = '\\t')\n",
    "names = pandas.read_csv('Unique_ModelSEED_Compound_Names.txt', sep = '\\t')\n",
    "compounds = json.load(open('2021-05-09_APF_nist thermodynamically described compounds for ModelSEED_01.json'))\n",
    "\n",
    "#display(ids.head(5))\n",
    "#display(names.head(5))\n",
    "\n",
    "# parse the compounds through the ModelSEED text files\n",
    "described_compounds = {}\n",
    "repeated_compounds = []\n",
    "for compound in compounds:\n",
    "    for index, modelseed_name in names.iterrows():\n",
    "        if str(compound).lower() == str(modelseed_name['External ID']).lower():\n",
    "            if modelseed_name['External ID'] not in described_compounds:\n",
    "                described_compounds[modelseed_name['External ID']] = modelseed_name['ModelSEED ID']\n",
    "                \n",
    "for described_compound, modelseed_id in described_compounds.items():\n",
    "    for index2, id in ids.iterrows():\n",
    "        if id['ModelSEED ID'] == modelseed_id:\n",
    "            if id['Source'] == 'KEGG':\n",
    "                #print(modelseed_name)\n",
    "                #print(modelseed_name['ModelSEED ID'])\n",
    "                #print(id['External ID'])\n",
    "                compound_information[described_compound] = {'ModelSEED ID': modelseed_id,\n",
    "                                                            'KEGG ID':id['External ID']}\n",
    "\n",
    "compounds_list = []\n",
    "for compound in compound_information.keys():\n",
    "    compounds_list.append(compound)\n",
    "    \n",
    "print('Identified compounds: ', len(compounds_list))\n",
    "print('repeated compounds: ', len(repeated_compounds))\n",
    "\n",
    "with open('2021-05-09_APF_KEGG and ModelSEED_IDs_01', 'w') as output:\n",
    "    json.dump(compound_information, output, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the requisite libraries\n",
    "import numpy\n",
    "import json\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "modelseed = json.load(open('compounds.json'))\n",
    "compounds = json.load(open('2021-05-09_APF_nist thermodynamically described compounds for ModelSEED_01.json'))\n",
    "\n",
    "empty_cells = ['null', ' null', numpy.nan, 'None', None]\n",
    "\n",
    "# parse the modelseed database and the list of thermodynamically described compounds\n",
    "described_compounds = {}\n",
    "alias_names = []\n",
    "for compound in compounds:\n",
    "    if compound not in described_compounds:  \n",
    "        #print(compound)\n",
    "        for compound2 in modelseed:\n",
    "            #print(compound2)\n",
    "            if compound2['is_obsolete'] == 0:\n",
    "                if compound2['aliases'] not in empty_cells:\n",
    "                    for entry in compound2['aliases']:\n",
    "                        if re.search('Name:', entry):\n",
    "                            alternative_name_string = re.sub('Name: ', '', entry).split('; ')\n",
    "                        if re.search('KEGG:', entry):\n",
    "                            kegg_id = re.sub('KEGG: ', '', entry).split('; ')\n",
    "                else:\n",
    "                    alternative_name_string = []\n",
    "\n",
    "                if str(compound).lower() == str(compound2['name']).lower() and compound not in described_compounds.keys():\n",
    "                    print('described 1: ', compound)\n",
    "                    described_compounds[compound] = {'ModelSEED ID': compound2['id'],\n",
    "                                                     'KEGG ID': kegg_id}\n",
    "                else:\n",
    "                    for name in alternative_name_string:\n",
    "                        try:\n",
    "                            if re.search(compound, name, re.IGNORECASE) and compound not in described_compounds.keys():\n",
    "                                print('described 2: ', compound)\n",
    "                                described_compounds[compound] = {'ModelSEED ID': compound2['id'],\n",
    "                                                                 'KEGG ID': kegg_id,\n",
    "                                                                 'alternative names': alternative_name_string}\n",
    "                        except:\n",
    "                            break\n",
    "    \n",
    "# export the acquired set of described compounds\n",
    "with open('2021-05-09_APF_described compounds in ModelSEED_01.json', 'w') as output:\n",
    "    json.dump(described_compounds, output, indent = 5)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import json\n",
    "import io\n",
    "\n",
    "compounds = json.load(open('2021-05-09_APF_nist thermodynamically described compounds for ModelSEED_01.json'))\n",
    "described_compounds = json.load(open('2021-05-09_APF_described compounds in ModelSEED_01.json'))\n",
    "\n",
    "described_compounds_list = []\n",
    "for compound in described_compounds:\n",
    "    described_compounds_list.append(compound)\n",
    "    \n",
    "print('Described compounds: ', len(described_compounds_list))\n",
    "\n",
    "compounds_list = []\n",
    "for compound in compounds:\n",
    "    compounds_list.append(compound)\n",
    "    \n",
    "print('Total compounds: ', len(compounds_list))\n",
    "\n",
    "undescribed_compounds = list(set(compounds_list) - set(described_compounds_list))\n",
    "\n",
    "print('Undescribed compounds: {}\\n'.format(len(undescribed_compounds)), '='*len('Undescribed compounds:'))\n",
    "for compound in undescribed_compounds:\n",
    "    print(compound)\n",
    "    \n",
    "    \n",
    "with io.open('2021-05-09_APF_NIST compounds absent from ModelSEED_01.csv', 'w', encoding=\"utf-8\") as output:\n",
    "    undescribed_compund_csv = pandas.DataFrame(undescribed_compounds)\n",
    "    undescribed_compund_csv.to_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftfy import fix_encoding\n",
    "import json\n",
    "\n",
    "nist = json.load(open('2021-05-06_NIST consolidated.json'))\n",
    "described_compounds = json.load(open('2021-05-09_APF_described compounds in ModelSEED_01.json'))\n",
    "\n",
    "described_compounds_list = []\n",
    "for compound in described_compounds:\n",
    "    described_compounds_list.append(compound)\n",
    "\n",
    "#print('Described compounds: {}\\n'.format(len(described_compounds_list)), described_compounds_list)\n",
    "    \n",
    "completely_described_reactions = {}\n",
    "undescribed_reactions = {}\n",
    "printed_enzyme = 'no'\n",
    "for enzyme, information in nist.items():\n",
    "    described_reactions = []\n",
    "    for reaction in information['reaction']:\n",
    "        reaction = fix_encoding(reaction)\n",
    "        reactants_list = []\n",
    "        products_list = []\n",
    "        compounds_list = []\n",
    "        if re.search('(=)', reaction):\n",
    "            reaction_split = reaction.split('=')\n",
    "            reactants_list = reaction_split[0].split(' + ')\n",
    "            products_list = reaction_split[1].split(' + ')\n",
    "            compounds = reactants_list + products_list\n",
    "            for element in compounds:\n",
    "                #print(element)\n",
    "                element = element.strip()\n",
    "                element = re.sub('(\\(aq\\)|\\(l\\)|\\(sln\\)|\\(liq\\))', '', element)\n",
    "                element = re.sub('(\\d\\s|\\d\\/\\d\\s)', '', element)\n",
    "                if element not in compounds_list:\n",
    "                    compounds_list.append(element)\n",
    "\n",
    "        #print(compounds_list)\n",
    "        described = all(compound in described_compounds_list for compound in compounds_list)\n",
    "        if described:\n",
    "            described_reactions.append(reaction)\n",
    "\n",
    "        '''else:\n",
    "            undescribed_reactions[element] = {'Enzyme': enzyme,\n",
    "                                              'Reaction': reaction,\n",
    "                                              'synonym': ''}\n",
    "        \n",
    "            continue'''\n",
    "        \n",
    "    completely_described_reactions[enzyme] = {'completely described reactions': described_reactions}\n",
    "    \n",
    "with open('2021-05-11_APF_completely described reactions for ModelSEED_01.json', 'w') as output:\n",
    "    json.dump(completely_described_reactions, output, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def isfloat(number):\n",
    "    try:\n",
    "        float(number)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "completely_described_reactions = json.load(open('2021-05-09_APF_completely described reactions for ModelSEED_01.json'))\n",
    "nist = json.load(open('2021-05-06_NIST consolidated.json'))\n",
    "\n",
    "described_enzymes_list = []\n",
    "for enzyme in completely_described_reactions:\n",
    "    described_enzymes_list.append(enzyme)\n",
    "    \n",
    "described_enzyme_data = {}\n",
    "for enzyme, information in nist.items():\n",
    "    unique_reactions = []\n",
    "    temperatures = []\n",
    "    phs = []\n",
    "    if enzyme in described_enzymes_list:\n",
    "        for reaction in information['reaction']:\n",
    "            if reaction not in unique_reactions:\n",
    "                unique_reactions.append(reaction)\n",
    "        \n",
    "        # calculate the average temperature \n",
    "        for temperature in information['experimental temperatures']:\n",
    "            if isfloat(temperature):\n",
    "                temperatures.append(float(temperature))\n",
    "        \n",
    "        if len(temperatures) > 0:\n",
    "            average_temperature = sum(temperatures) / len(temperatures)\n",
    "        else:\n",
    "            average_temperautre = 'nan'\n",
    "            \n",
    "        # calculate the average ph \n",
    "        for ph in information['experimental phs']:\n",
    "            if isfloat(ph):\n",
    "                phs.append(float(ph))\n",
    "        \n",
    "        if len(temperatures) > 0:\n",
    "            average_ph = sum(phs) / len(phs)\n",
    "        else:\n",
    "            average_ph = 'nan'\n",
    "        \n",
    "\n",
    "        \n",
    "    described_enzyme_data[enzyme] = {'unique reactions': unique_reactions,\n",
    "                                    'average keq': information['Keq']['keq average'],\n",
    "                                    'average enthalpy': information['Enthalpy']['enthalpy average'],\n",
    "                                    'average temperature kelvin': average_temperature,\n",
    "                                    'average pH': average_ph}\n",
    "\n",
    "with open('2021-05-09_APF_ModelSEED described enzymes_01.json', 'w') as output:\n",
    "    json.dump(described_enzyme_data, output, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "nist_data = json.load(open('2021-05-09_APF_ModelSEED described enzymes_01.json'))\n",
    "\n",
    "     \n",
    "with open('2021-05-10_APF_ModelSEED formatted reactions.tsv', 'w') as output:\n",
    "    output.write('\\t'.join(['ID', 'Names','Equation', 'Equation defintion', '\\n']))\n",
    "    for enzyme, information in nist_data.items():\n",
    "        for reaction in information['unique reactions']:            \n",
    "            output.write('\\t'.join([information['id'],\n",
    "                                    enzyme,\n",
    "                                    equation,\n",
    "                                    reaction) + '\\n')\n",
    "    output.close()\n",
    "                                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftfy import fix_encoding\n",
    "import json\n",
    "\n",
    "nist_reactions = json.load(open('2021-05-09_APF_ModelSEED described enzymes_01.json'))\n",
    "nist_compounds = json.load(open('2021-05-09_APF_described compounds in ModelSEED_01.json'))\n",
    "\n",
    "for enzyme, information in nist_reactions.items():\n",
    "    for reaction in information['unique reactions']:        \n",
    "        reaction = fix_encoding(reaction)\n",
    "        reactants_list = []\n",
    "        products_list = []\n",
    "        compounds_list = []\n",
    "        if re.search('(=)', reaction):\n",
    "            reaction_split = reaction.split('=')\n",
    "            reactants_list = reaction_split[0].split(' + ')\n",
    "            products_list = reaction_split[1].split(' + ')\n",
    "            reaction_string = ''\n",
    "            for element in reactants_list:\n",
    "                #print(element)\n",
    "                element = element.strip()\n",
    "                element = re.sub('(\\(aq\\)|\\(l\\)|\\(sln\\)|\\(liq\\))', '', element)\n",
    "                element = re.sub('(\\d\\s|\\d\\/\\d\\s)', '', element)\n",
    "                if element in nist_compounds.keys():\n",
    "                    element = nist_compounds[element]['ModelSEED ID']\n",
    "                    reaction_string += element\n",
    "                    \n",
    "            product_string = ''\n",
    "            for element in products_list:\n",
    "                #print(element)\n",
    "                element = element.strip()\n",
    "                element = re.sub('(\\(aq\\)|\\(l\\)|\\(sln\\)|\\(liq\\))', '', element)\n",
    "                element = re.sub('(\\d\\s|\\d\\/\\d\\s)', '', element)\n",
    "                if element in nist_compounds.keys():\n",
    "                    element = nist_compounds[element]['ModelSEED ID']\n",
    "                    \n",
    "                    \n",
    "with open('2021-05-10_APF_ModelSEED ID described reactions_01.json') as output:\n",
    "    json.dump( , output, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftfy import fix_encoding\n",
    "import json\n",
    "import re\n",
    "\n",
    "nist_reactions = json.load(open('2021-05-09_APF_ModelSEED described enzymes_01.json'))\n",
    "nist_compounds = json.load(open('2021-05-09_APF_described compounds in ModelSEED_01.json'))\n",
    "described_reactions = json.load(open('2021-05-09_APF_nist thermodynamically described reactions for ModelSEED_01.json'))\n",
    "\n",
    "total_complete_reactions = []\n",
    "exchanged_reactions = []\n",
    "to_modelseed_reactions = {}\n",
    "for enzyme, information in nist_reactions.items():\n",
    "    #if enzyme in described_reactions.keys():\n",
    "    #print('\\n\\n{}\\n'.format(enzyme))\n",
    "    #for modelseed_id in information['ModelSEED ID']:\n",
    "    complete_reactions = []\n",
    "    for reaction in information['unique reactions']:\n",
    "        reaction = fix_encoding(reaction)\n",
    "        reaction = re.sub('(\\(aq\\)|\\(l\\)|\\(sln\\)|\\(liq\\))', '', reaction)\n",
    "        #print('reaction: {}'.format(reaction))\n",
    "\n",
    "        reactants_list = []\n",
    "        products_list = []\n",
    "        compounds_list = []\n",
    "        if re.search('(=)', reaction):\n",
    "            reaction_split = reaction.split('=')\n",
    "            reactants_list = reaction_split[0].split(' + ')\n",
    "            products_list = reaction_split[1].split(' + ')\n",
    "            reactants = []\n",
    "            for element in reactants_list:\n",
    "                #print(element)\n",
    "                element = element.strip()\n",
    "                element = re.sub('(\\(aq\\)|\\(l\\)|\\(sln\\)|\\(liq\\))', '', element)\n",
    "                element = re.sub('(\\d\\s|\\d\\/\\d\\s)', '', element)\n",
    "                if element in nist_compounds.keys():\n",
    "                    reactants.append(nist_compounds[element]['ModelSEED ID'])\n",
    "\n",
    "                else:\n",
    "                    reactants.append(element)\n",
    "\n",
    "            products = []\n",
    "            for element in products_list:\n",
    "                #print(element)\n",
    "                element = element.strip()\n",
    "                element = re.sub('(\\(aq\\)|\\(l\\)|\\(sln\\)|\\(liq\\))', '', element)\n",
    "                element = re.sub('(\\d\\s|\\d\\/\\d\\s)', '', element)\n",
    "                if element in nist_compounds.keys():\n",
    "                    products.append(nist_compounds[element]['ModelSEED ID'])\n",
    "\n",
    "                else:\n",
    "                    products.append(element)\n",
    "\n",
    "            compounds = reactants + products\n",
    "        \n",
    "        else:\n",
    "            print('incorrect reaction: ', reaction)\n",
    "\n",
    "        if len(reactants) > 1:\n",
    "            reactants_string = ' + '.join(reactants)\n",
    "            #print('yes')\n",
    "\n",
    "        elif len(reactants) == 1:\n",
    "            reactants_string = reactants[0]\n",
    "\n",
    "        else:\n",
    "            print('ERROR: The reaction __ {} __ has zero reactants'.format(reaction))\n",
    "\n",
    "        #print(products)\n",
    "        if len(products) > 1:\n",
    "            products_string = ' + '.join(products)\n",
    "\n",
    "        elif len(products) == 1:\n",
    "            products_string = products[0]\n",
    "\n",
    "        else:\n",
    "            print('\\tERROR: The reaction __ {} __ has zero products'.format(reaction))\n",
    "            print('\\t{}'.format(products_list))\n",
    "\n",
    "        #print('''reaction_string: {}\n",
    "        #products_string: {}'''.format(type(reaction_string), type(products_string)))\n",
    "\n",
    "        final_reaction = reactants_string + ' = ' + products_string\n",
    "        #print('exchanged reaction: {}'.format(final_reaction))\n",
    "        exchanged_reactions.append(final_reaction)\n",
    "\n",
    "        if all('cpd' in compound for compound in compounds):\n",
    "            complete_reactions.append(final_reaction)\n",
    "\n",
    "        \n",
    "        '''for compound, ids in nist_compounds.items():\n",
    "            if re.search(compound, reaction, re.IGNORECASE):\n",
    "                if not re.search('\\w {}'.format(compound), reaction, re.IGNORECASE):\n",
    "                reaction = re.sub(compound, ids['ModelSEED ID'], reaction)'''\n",
    "\n",
    "    to_modelseed_reactions[enzyme] = complete_reactions\n",
    "    total_complete_reactions += complete_reactions\n",
    "    \n",
    "print('Total reactions: {}'.format(len(exchanged_reactions)))                    \n",
    "print('Parsed and exchaged reactions: {}'.format(len(total_complete_reactions)))\n",
    "print('Previously complete reactions: {}'.format(len(described_reactions.keys())))\n",
    "#print(complete_reactions)\n",
    "\n",
    "\n",
    "'''with open('2021-05-11_APF_NIST to ModelSEED_01.json', 'w') as output:\n",
    "    json.dump(to_modelseed_reactions, output, indent = 4)'''\n",
    "\n",
    "\n",
    "'''with open('2021-05-10_APF_ModelSEED ID described reactions_01.json') as output:\n",
    "    json.dump( , output, indent = 4)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "described_reactions = json.load(open('2021-05-11_APF_NIST to ModelSEED, in form_01.json'))\n",
    "\n",
    "tsv_lines = []\n",
    "for enzyme, information in described_reactions.items():\n",
    "    for reaction in information:\n",
    "        tsv_lines.append('\\t'.join([enzyme, reaction]))\n",
    "        \n",
    "print('Total reactions: {}'.format(len(tsv_lines)))  \n",
    "        \n",
    "tsv_file = open('2021-05-11_APF_NIST to ModelSEED, per reaction, in form_01.tsv', 'w')\n",
    "tsv_file.write('\\t'.join(['ID', 'Equation']) + '\\n' + '\\n'.join(tsv_lines))\n",
    "tsv_file.close()    \n",
    "\n",
    "'''with open('2021-05-10_APF_ModelSEED ID described reactions_01.json') as output:\n",
    "    json.dump( , output, indent = 4)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ftfy import fix_encoding\n",
    "import json\n",
    "import re\n",
    "\n",
    "nist_reactions = json.load(open('2021-05-09_APF_ModelSEED described enzymes_01.json'))\n",
    "nist_compounds = json.load(open('2021-05-09_APF_described compounds in ModelSEED_01.json'))\n",
    "described_reactions = json.load(open('2021-05-09_APF_nist thermodynamically described reactions for ModelSEED_01.json'))\n",
    "\n",
    "total_complete_reactions = []\n",
    "exchanged_reactions = []\n",
    "to_modelseed_reactions = {}\n",
    "for enzyme, information in nist_reactions.items():\n",
    "    #if enzyme in described_reactions.keys():\n",
    "    #print('\\n\\n{}\\n'.format(enzyme))\n",
    "    #for modelseed_id in information['ModelSEED ID']:\n",
    "    complete_reactions = []\n",
    "    for reaction in information['unique reactions']:\n",
    "        reaction = fix_encoding(reaction)\n",
    "        reaction = re.sub('(\\(aq\\)|\\(l\\)|\\(sln\\)|\\(liq\\))', '', reaction)\n",
    "        #print('reaction: {}'.format(reaction))\n",
    "\n",
    "        reactants_list = []\n",
    "        products_list = []\n",
    "        compounds_list = []\n",
    "        if re.search('(=)', reaction):\n",
    "            reaction_split = reaction.split('=')\n",
    "            reactants_list = reaction_split[0].split(' + ')\n",
    "            products_list = reaction_split[1].split(' + ')\n",
    "            reactants = []\n",
    "            for element in reactants_list:\n",
    "                #print(element)\n",
    "                element = element.strip()\n",
    "                if re.search('(\\d\\s|\\d\\/\\d\\s)', element):\n",
    "                    coefficient = re.compile('(\\d\\s|\\d\\/\\d\\s)')\n",
    "                    coefficient = coefficient.findall(element)[0]\n",
    "                else:\n",
    "                    coefficient = ''\n",
    "                    \n",
    "                element = re.sub('(\\d\\s|\\d\\/\\d\\s)', '', element)\n",
    "                if element in nist_compounds.keys():\n",
    "                    reactants.append(coefficient + nist_compounds[element]['ModelSEED ID'])\n",
    "\n",
    "                else:\n",
    "                    reactants.append(element)\n",
    "\n",
    "            products = []\n",
    "            for element in products_list:\n",
    "                #print(element)\n",
    "                element = element.strip()\n",
    "                if re.search('(\\d\\s|\\d\\/\\d\\s)', element):\n",
    "                    coefficient = re.compile('(\\d\\s|\\d\\/\\d\\s)')\n",
    "                    coefficient = coefficient.findall(element)[0]\n",
    "                else:\n",
    "                    coefficient = ''\n",
    "                    \n",
    "                element = re.sub('(\\d\\s|\\d\\/\\d\\s)', '', element)\n",
    "                if element in nist_compounds.keys():\n",
    "                    products.append(coefficient + nist_compounds[element]['ModelSEED ID'])\n",
    "\n",
    "                else:\n",
    "                    products.append(element)\n",
    "\n",
    "            compounds = reactants + products\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            print('incorrect reaction: ', reaction)\n",
    "\n",
    "        if len(reactants) > 1:\n",
    "            reactants_string = ' + '.join(reactants)\n",
    "            #print('yes')\n",
    "\n",
    "        elif len(reactants) == 1:\n",
    "            reactants_string = reactants[0]\n",
    "\n",
    "        else:\n",
    "            print('ERROR: The reaction __ {} __ has zero reactants'.format(reaction))\n",
    "\n",
    "        #print(products)\n",
    "        if len(products) > 1:\n",
    "            products_string = ' + '.join(products)\n",
    "\n",
    "        elif len(products) == 1:\n",
    "            products_string = products[0]\n",
    "\n",
    "        else:\n",
    "            print('\\tERROR: The reaction __ {} __ has zero products'.format(reaction))\n",
    "            print('\\t{}'.format(products_list))\n",
    "\n",
    "        reaction_string = reactants_string + ' <=> ' + products_string\n",
    "            \n",
    "        # arrange the reaction equilibrium arrow and stoichiometric coefficients for ModelSEED                        \n",
    "        if re.search('((?<!\\w)\\d\\s|\\d\\/\\d\\s)', reaction_string):\n",
    "            reaction_string = re.sub('((?<!\\w)\\d\\s|\\d\\/\\d\\s)', r'(\\1) ', reaction_string)\n",
    "            reaction_string = re.sub('(?<=\\d)(\\s)(?=\\))', '', reaction_string)\n",
    "            \n",
    "        if re.search('(?<=>|\\+)(\\s)(?=\\w)', reaction_string):\n",
    "            reaction_string = re.sub('(?<=>|\\+)(\\s)(?=\\w)', ' (1) ', reaction_string)\n",
    "\n",
    "        if not re.search('^( \\d|\\()', reaction_string):\n",
    "            reaction_string = '(1) ' + reaction_string\n",
    "            \n",
    "        reaction_string = re.sub('(?<=\\w)(\\s)(?=<|\\+)', '[0] ', reaction_string)\n",
    "        reaction_string += '[0]'\n",
    "            \n",
    "        #print('''reaction_string: {}\n",
    "        #products_string: {}'''.format(type(reaction_string), type(products_string)))\n",
    "        #print('exchanged reaction: {}'.format(final_reaction))\n",
    "        \n",
    "        \n",
    "        exchanged_reactions.append(reaction_string)\n",
    "        if all('cpd' in compound for compound in compounds):\n",
    "            complete_reactions.append(reaction_string)\n",
    "\n",
    "        \n",
    "        '''for compound, ids in nist_compounds.items():\n",
    "            if re.search(compound, reaction, re.IGNORECASE):\n",
    "                if not re.search('\\w {}'.format(compound), reaction, re.IGNORECASE):\n",
    "                reaction = re.sub(compound, ids['ModelSEED ID'], reaction)'''\n",
    "\n",
    "    to_modelseed_reactions[enzyme] = complete_reactions\n",
    "    total_complete_reactions += complete_reactions\n",
    "    \n",
    "print('Total reactions: {}'.format(len(exchanged_reactions)))                    \n",
    "print('Parsed and exchaged reactions: {}'.format(len(total_complete_reactions)))\n",
    "print('Previously complete reactions: {}'.format(len(described_reactions.keys())))\n",
    "#print(complete_reactions)\n",
    "\n",
    "\n",
    "'''with open('2021-05-11_APF_NIST to ModelSEED, in form_01.json', 'w') as output:\n",
    "    json.dump(to_modelseed_reactions, output, indent = 4)'''\n",
    "\n",
    "    \n",
    "tsv_lines = []\n",
    "enzyme_id_dictionary = {}\n",
    "id_number = 0\n",
    "for enzyme, information in to_modelseed_reactions.items():\n",
    "    enzyme_id_dictionary[enzyme] = id\n",
    "    for reaction in information:\n",
    "        id = 'rxn{}'.format(id_number)\n",
    "        tsv_lines.append('\\t'.join([id, reaction]))\n",
    "        id_number += 1\n",
    "    \n",
    "print('Total reactions: {}'.format(len(tsv_lines)))  \n",
    "        \n",
    "tsv_file = open('2021-05-11_APF_NIST to ModelSEED, in form, with ids_01.tsv', 'w')\n",
    "tsv_file.write('\\t'.join(['ID', 'Equation']) + '\\n' + '\\n'.join(tsv_lines))\n",
    "tsv_file.close()  \n",
    "    \n",
    "\n",
    "'''with open('2021-05-10_APF_ModelSEED ID described reactions_01.json') as output:\n",
    "    json.dump( , output, indent = 4)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Add_new_curated_compounds.py\" and \"Add_new_curated_reactions.py\" files were used to evaluate the data contribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add_new_curated_compounds.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Takes one argument, the path to and including reactions file\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os, sys, re, copy\n",
    "from csv import DictReader\n",
    "from collections import OrderedDict\n",
    "temp=list();\n",
    "header=True;\n",
    "\n",
    "dry_run = True\n",
    "if(\"save\" in sys.argv):\n",
    "    dry_run = False\n",
    "\n",
    "if(len(sys.argv)<2 or os.path.isfile(sys.argv[1]) is False):\n",
    "    print(\"Takes one argument, the path to and including reactions file\")\n",
    "    sys.exit()\n",
    "\n",
    "compounds_file=sys.argv[1]\n",
    "curation_source = compounds_file.split('\\\\')[-2]\n",
    "\n",
    "sys.path.append('../../../Libs/Python')\n",
    "from BiochemPy import Reactions, Compounds, InChIs\n",
    "\n",
    "compounds_helper = Compounds()\n",
    "compounds_dict = compounds_helper.loadCompounds()\n",
    "\n",
    "names_dict = compounds_helper.loadNames()\n",
    "searchnames_dict = dict()\n",
    "all_names_dict = dict()\n",
    "new_name_count = dict()\n",
    "for msid in sorted(names_dict):\n",
    "    for name in names_dict[msid]:\n",
    "        all_names_dict[name]=1\n",
    "\n",
    "        searchname = compounds_helper.searchname(name)\n",
    "        #Avoid redundancy where possible\n",
    "        if(searchname not in searchnames_dict):\n",
    "            searchnames_dict[searchname]=msid\n",
    "\n",
    "original_alias_dict=compounds_helper.loadMSAliases()\n",
    "source_alias_dict = dict()\n",
    "all_aliases = dict()\n",
    "new_alias_count = dict()\n",
    "for msid in original_alias_dict:\n",
    "    for source in original_alias_dict[msid]:\n",
    "        if(source not in source_alias_dict):\n",
    "            source_alias_dict[source]=dict()\n",
    "\n",
    "        for alias in original_alias_dict[msid][source]:\n",
    "            if(alias not in all_aliases):\n",
    "                all_aliases[alias]=dict()\n",
    "            all_aliases[alias][msid]=1\n",
    "\n",
    "            if(alias not in source_alias_dict[source]):\n",
    "                source_alias_dict[source][alias]=list()\n",
    "            source_alias_dict[source][alias].append(msid)\n",
    "\n",
    "for alias in all_aliases:\n",
    "    all_aliases[alias]=sorted(all_aliases[alias])\n",
    "\n",
    "Structures_Dict = compounds_helper.loadStructures([\"InChI\",\"SMILE\"],[\"KEGG\",\"MetaCyc\"])\n",
    "all_inchis=dict()\n",
    "all_aliases_InChIs=dict()\n",
    "for alias in Structures_Dict['InChI']:\n",
    "    if('Charged' in Structures_Dict['InChI'][alias]):\n",
    "        for struct in Structures_Dict['InChI'][alias]['Charged']:\n",
    "            if(struct not in all_inchis):\n",
    "                all_inchis[struct]=list()\n",
    "            all_inchis[struct].append(alias)\n",
    "\n",
    "            if(alias not in all_aliases_InChIs):\n",
    "                all_aliases_InChIs[alias]=list()\n",
    "            all_aliases_InChIs[alias].append(struct)\n",
    "    elif('Original' in Structures_Dict['InChI'][alias]):\n",
    "        for struct in Structures_Dict['InChI'][alias]['Original']:\n",
    "            if(struct not in all_inchis):\n",
    "                all_inchis[struct]=list()\n",
    "            all_inchis[struct].append(alias)\n",
    "\n",
    "            if(alias not in all_aliases_InChIs):\n",
    "                all_aliases_InChIs[alias]=list()\n",
    "            all_aliases_InChIs[alias].append(struct)\n",
    "\n",
    "all_smiles=dict()\n",
    "all_aliases_SMILEs=dict()\n",
    "for alias in Structures_Dict['SMILE']:\n",
    "    if('Charged' in Structures_Dict['SMILE'][alias]):\n",
    "        for struct in Structures_Dict['SMILE'][alias]['Charged']:\n",
    "            if(struct not in all_smiles):\n",
    "                all_smiles[struct]=list()\n",
    "            all_smiles[struct].append(alias)\n",
    "\n",
    "            if(alias not in all_aliases_SMILEs):\n",
    "                all_aliases_SMILEs[alias]=list()\n",
    "            all_aliases_SMILEs[alias].append(struct)\n",
    "    elif('Original' in Structures_Dict['SMILE'][alias]):\n",
    "        for struct in Structures_Dict['SMILE'][alias]['Original']:\n",
    "            if(struct not in all_smiles):\n",
    "                all_smiles[struct]=list()\n",
    "            all_smiles[struct].append(alias)\n",
    "\n",
    "            if(alias not in all_aliases_SMILEs):\n",
    "                all_aliases_SMILEs[alias]=list()\n",
    "            all_aliases_SMILEs[alias].append(struct)\n",
    "\n",
    "#Find last identifier and increment\n",
    "last_identifier = list(sorted(compounds_dict))[-1]\n",
    "identifier_count = int(re.sub('^cpd','',last_identifier))\n",
    "\n",
    "Default_Cpd = OrderedDict({ \"id\":\"cpd00000\",\"name\":\"null\",\"abbreviation\":\"null\",\"aliases\":\"null\",\n",
    "                             \"formula\":\"null\",\"mass\":10000000,\"charge\":0,\n",
    "                             \"deltag\":10000000.0,\"deltagerr\":10000000.0,\"pka\":\"\",\"pkb\":\"\",\n",
    "                             \"inchikey\":\"\",\"smiles\":\"\",\n",
    "                             \"is_cofactor\":0,\"is_core\":0,\"is_obsolete\":0,\n",
    "                             \"abstract_compound\":\"null\",\"comprised_of\":\"null\",\"linked_compound\":\"null\",\n",
    "                             \"notes\":[],\"source\":\"\" })\n",
    "New_Cpd_Count=dict()\n",
    "Matched_Cpd_Count=dict()\n",
    "Headers=list()\n",
    "with open(compounds_file) as fh:\n",
    "    for line in fh.readlines():\n",
    "        line=line.strip()\n",
    "        if(len(Headers)==0):\n",
    "            Headers=line.split('\\t')\n",
    "            continue\n",
    "\n",
    "        cpd=dict()\n",
    "        array=line.split('\\t',len(Headers))\n",
    "        for i in range(len(Headers)):\n",
    "            cpd[Headers[i].lower()]=array[i]\n",
    "\n",
    "        (matched_cpd,matched_src)=(None,None)\n",
    "\n",
    "        #Check that the Structure doesn't already exist, first as InChI, then as SMILE\n",
    "        if(matched_cpd is None and cpd['inchi'] and cpd['inchi'] in all_inchis):\n",
    "\n",
    "            msids = dict()\n",
    "            for alias in all_inchis[cpd['inchi']]:\n",
    "\n",
    "                #The structures are taken from their sources and the corresponding alias may not yet be registered\n",
    "                if(alias not in all_aliases):\n",
    "                    continue\n",
    "\n",
    "                for msid in all_aliases[alias]:\n",
    "                    msids[msid]=1\n",
    "\n",
    "            msids=list(sorted(msids))\n",
    "            if(len(msids)>0):\n",
    "                matched_cpd=msids[0]\n",
    "                matched_src='InChI'\n",
    "\n",
    "        elif(matched_cpd is None and cpd['smile'] and cpd['smile'] in all_smiles):\n",
    "\n",
    "            msids = dict()\n",
    "            for alias in all_smiles[cpd['smile']]:\n",
    "                #The structures are taken from their sources and the corresponding alias may not yet be registered\n",
    "                if(alias not in all_aliases):\n",
    "                    continue\n",
    "\n",
    "                for msid in all_aliases[alias]:\n",
    "                    msids[msid]=1\n",
    "\n",
    "            msids=list(sorted(msids))\n",
    "            if(len(msids)>0):\n",
    "                matched_cpd=msids[0]\n",
    "                matched_src='SMILE'\n",
    "\n",
    "        #Then check that the Name doesn't already exist\n",
    "        elif(matched_cpd is None):\n",
    "            msids=dict()\n",
    "            for name in cpd['names'].split('|'):\n",
    "                searchname = compounds_helper.searchname(name)\n",
    "                if(searchname in searchnames_dict):\n",
    "                    msids[searchnames_dict[searchname]]=1\n",
    "            msids=list(sorted(msids))\n",
    "            if(len(msids)>0):\n",
    "                matched_cpd=msids[0]\n",
    "                matched_src='NAMES'\n",
    "\n",
    "        if(matched_cpd is not None):\n",
    "            \n",
    "            if(matched_src not in Matched_Cpd_Count):\n",
    "                Matched_Cpd_Count[matched_src]=list()\n",
    "            Matched_Cpd_Count[matched_src].append(matched_cpd)\n",
    "\n",
    "            #Regardless of match-type, add new names\n",
    "            #NB at this point, names shouldn't match _anything_ already in the database\n",
    "            #Names are saved separately as part of the aliases at the end of the script\n",
    "            for name in cpd['names'].split('|'):\n",
    "                if(name not in all_names_dict):\n",
    "                    #Possible for there to be no names in biochemistry?\n",
    "                    if(matched_cpd not in names_dict):\n",
    "                        names_dict[matched_cpd]=list()\n",
    "                    names_dict[matched_cpd].append(name)\n",
    "                    all_names_dict[name]=1\n",
    "                    new_name_count[matched_cpd]=1\n",
    "\n",
    "            #print warning if multiple structures\n",
    "            if(cpd['inchi'] in all_inchis):\n",
    "                if(cpd['id'] not in all_aliases_InChIs or cpd['id'] not in all_inchis[cpd['inchi']]):\n",
    "                    print(\"Warning: InChI structure for \"+cpd['id']+\" assigned to different compounds: \"+\",\".join(all_inchis[cpd['inchi']]))\n",
    "\n",
    "            #print warning if multiple structures\n",
    "            if(cpd['smile'] in all_smiles):\n",
    "                if(cpd['ID'] not in all_aliases_SMILEs or cpd['id'] not in all_smiles[cpd['smile']]):\n",
    "                    print(\"Warning: SMILE structure for \"+cpd['id']+\" assigned to different compounds: \"+\",\".join(all_smiles[cpd['smile']]))\n",
    "                \n",
    "            #if matching structure or name, add ID to aliases\n",
    "            if(matched_src != 'ID'):\n",
    "                if(matched_cpd not in original_alias_dict):\n",
    "                    original_alias_dict[matched_cpd]=dict()\n",
    "                if(matched_cpd in original_alias_dict and curation_source not in original_alias_dict[matched_cpd]):\n",
    "                    original_alias_dict[matched_cpd][curation_source]=list()\n",
    "                original_alias_dict[matched_cpd][curation_source].append(cpd['id'])\n",
    "                new_alias_count[matched_cpd]=1\n",
    "\n",
    "            #Update source type\n",
    "            compounds_dict[matched_cpd]['source']='Primary Database'\n",
    "\n",
    "        else:\n",
    "\n",
    "            #New Compound!\n",
    "            #Generate new identifier\n",
    "            identifier_count+=1\n",
    "            new_identifier = 'cpd'+str(identifier_count)\n",
    "\n",
    "            new_cpd = copy.deepcopy(Default_Cpd)\n",
    "            new_cpd['id']=new_identifier\n",
    "            new_cpd['mass']=float(cpd['mass'])\n",
    "            new_cpd['charge']=int(cpd['charge'])\n",
    "            new_cpd['formula']=cpd['formula']\n",
    "\n",
    "            #Add new identifier with original ID as alias\n",
    "            original_alias_dict[new_cpd['id']]={curation_source:[cpd['id']]}\n",
    "            new_alias_count[new_cpd['id']]=1\n",
    "\n",
    "            #Add new names\n",
    "            #Names are saved separately as part of the aliases at the end of the script\n",
    "            for name in cpd['names'].split('|'):\n",
    "                if(new_cpd['name']=='null'):\n",
    "                    new_cpd['name']=name\n",
    "                    new_cpd['abbreviation']=name\n",
    "\n",
    "                if(name not in all_names_dict):\n",
    "                    #Possible for there to be no names in biochemistry?\n",
    "                    if(new_cpd['id'] not in names_dict):\n",
    "                        names_dict[new_cpd['id']]=list()\n",
    "                    names_dict[new_cpd['id']].append(name)\n",
    "                    all_names_dict[name]=1\n",
    "                    new_name_count[new_cpd['id']]=1\n",
    "\n",
    "            #If no names at all\n",
    "            if(new_cpd['name']=='null'):\n",
    "                new_cpd['name']=cpd['id']\n",
    "                new_cpd['abbreviation']=cpd['id']\n",
    "\n",
    "            #Add source type\n",
    "            new_cpd['source']='Primary Database'\n",
    "            compounds_dict[new_cpd['id']]=new_cpd\n",
    "            New_Cpd_Count[new_cpd['id']]=1\n",
    "\n",
    "#Here, for matches, re-write names and aliases\n",
    "print(\"Compounds matched via:\")\n",
    "for src in sorted(Matched_Cpd_Count):\n",
    "    print(\"\\t\"+src+\": \"+str(len(Matched_Cpd_Count[src])))\n",
    "print(\"Saving additional names for \"+str(len(new_name_count))+\" compounds\")\n",
    "if(dry_run is False):\n",
    "    compounds_helper.saveNames(names_dict)\n",
    "print(\"Saving additional \"+curation_source+\" aliases for \"+str(len(new_alias_count))+\" compounds\")\n",
    "if(dry_run is False):\n",
    "    compounds_helper.saveAliases(original_alias_dict)\n",
    "print(\"Saving \"+str(len(New_Cpd_Count))+\" new compounds from \"+curation_source)\n",
    "if(dry_run is False):\n",
    "    compounds_helper.saveCompounds(compounds_dict)\n",
    "\n",
    "#Scripts to run afterwards\n",
    "#./Merge_Formulas.py\n",
    "#./Update_Compound_Aliases.py\n",
    "#../Structures/List_ModelSEED_Structures.py\n",
    "#../Structures/Update_Compound_Structures_Formulas_Charge.py\n",
    "#./Rebalance_Reactions.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add_new_curated_reactions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import os, sys, re, copy\n",
    "\n",
    "if(len(sys.argv)!=2 or os.path.isfile(sys.argv[1]) is False):\n",
    "    print(\"Takes one argument, the path to and including reactions file\")\n",
    "    sys.exit()\n",
    "\n",
    "reactions_file=sys.argv[1]\n",
    "curation_source = reactions_file.split('/')[-2]\n",
    "compound_source = \"ModelSEED\"\n",
    "\n",
    "sys.path.append('../../Libs/Python')\n",
    "from BiochemPy import Reactions, Compounds, InChIs\n",
    "\n",
    "compounds_helper = Compounds()\n",
    "compounds_dict = compounds_helper.loadCompounds()\n",
    "reactions_helper = Reactions()\n",
    "reactions_dict = reactions_helper.loadReactions()\n",
    "reactions_codes = reactions_helper.generateCodes(reactions_dict)\n",
    "\n",
    "Default_Rxn = {\"id\":\"cpd00001\",\"name\":\"null\",\"abbreviation\":\"null\",\"aliases\":[],\n",
    "               \"code\":\"null\",\"stoichiometry\":\"null\",\"equation\":\"null\",\"definition\":\"null\",\n",
    "               \"reversibility\":\"=\",\"direction\":\"=\",\"deltag\":\"10000000\",\"deltagerr\":\"10000000\",\n",
    "               \"status\":\"NB\",\"is_obsolete\":0,\"is_transport\":0,\n",
    "               \"abstract_reaction\":\"null\",\"pathways\":\"null\",\"ec_numbers\":\"null\",\n",
    "               \"compound_ids\":\"null\",\"linked_reaction\":\"null\",\"notes\":[],\"source\":\"\"}\n",
    "\n",
    "Compounds_Alias_Dict=compounds_helper.loadMSAliases()\n",
    "Source_Alias_Dict = dict()\n",
    "for msid in Compounds_Alias_Dict:\n",
    "    for source in Compounds_Alias_Dict[msid]:\n",
    "        if(source not in Source_Alias_Dict):\n",
    "            Source_Alias_Dict[source]=dict()\n",
    "        for alias in Compounds_Alias_Dict[msid][source]:\n",
    "            if(alias not in Source_Alias_Dict[source]):\n",
    "                Source_Alias_Dict[source][alias]=list()\n",
    "            Source_Alias_Dict[source][alias].append(msid)\n",
    "\n",
    "original_rxn_alias_dict=reactions_helper.loadMSAliases()\n",
    "New_Alias_Count=dict()\n",
    "\n",
    "Names_Dict = reactions_helper.loadNames()\n",
    "All_Names = dict()\n",
    "New_Name_Count=dict()\n",
    "for msid in sorted(Names_Dict):\n",
    "    for name in Names_Dict[msid]:\n",
    "        All_Names[name]=1\n",
    "\n",
    "ECs_Dict = reactions_helper.loadECs()\n",
    "All_ECs = dict()\n",
    "New_EC_Count=dict()\n",
    "for msid in sorted(ECs_Dict):\n",
    "    for name in ECs_Dict[msid]:\n",
    "        All_ECs[name]=1\n",
    "\n",
    "#Find last identifier and increment\n",
    "last_identifier = list(sorted(reactions_dict))[-1]\n",
    "identifier_count = int(re.sub('^rxn','',last_identifier))\n",
    "\n",
    "#If a reaction, after removing cpd redundancy, is empty\n",
    "#We use a placeholder\n",
    "Empty_Rxn_ID=\"rxn14003\"\n",
    "\n",
    "New_Rxn_Count=dict()\n",
    "Headers=list()\n",
    "rxns=list()\n",
    "missing_cpds=dict()\n",
    "with open(reactions_file) as fh:\n",
    "    for line in fh.readlines():\n",
    "        line=line.strip()\n",
    "        if(len(Headers)==0):\n",
    "            Headers=line.split('\\t')\n",
    "            continue\n",
    "\n",
    "        rxn=dict()\n",
    "        array=line.split('\\t',len(Headers))\n",
    "        for i in range(len(Headers)):\n",
    "            rxn[Headers[i].upper()]=array[i]\n",
    "\n",
    "        #Retrieve identifiers from within equation\n",
    "        #Split based on whitespace, and remove compartment index\n",
    "        original_cpd_array=rxn['EQUATION'].split(' ')\n",
    "\n",
    "        new_cpd_array=list()\n",
    "        for i in range(len(original_cpd_array)):\n",
    "            #Assumes MS IDs\n",
    "            if('cpd' not in original_cpd_array[i]):\n",
    "                continue\n",
    "\n",
    "            if(re.search('\\[[01]\\]$',original_cpd_array[i])):\n",
    "                new_cpd_array.append(re.sub('\\[[01]\\]$','',original_cpd_array[i]))\n",
    "            else:\n",
    "                new_cpd_array.append(original_cpd_array[i])\n",
    "\n",
    "        all_matched=True\n",
    "        for new_cpd in new_cpd_array:\n",
    "            #Assume MS identifiers for time being\n",
    "            if(new_cpd in compounds_dict):\n",
    "                msid = new_cpd\n",
    "\n",
    "#            if(compound_source in Source_Alias_Dict and new_cpd in Source_Alias_Dict[compound_source]):\n",
    "#                msid = sorted(Source_Alias_Dict[compound_source][new_cpd])[0]\n",
    "\n",
    "                #set boundary\n",
    "                bound_msid=msid+\"[\"\n",
    "                bound_cpd=new_cpd+\"[\"\n",
    "                esc_cpd = re.escape(bound_cpd)\n",
    "                \n",
    "                eqn_array = rxn['EQUATION'].split(\" \")\n",
    "                new_eqn_array = list()\n",
    "                for entry in eqn_array:\n",
    "                    entry = re.sub(esc_cpd,bound_msid,entry)\n",
    "                    new_eqn_array.append(entry)\n",
    "                rxn['EQUATION'] = \" \".join(new_eqn_array)\n",
    "            else:\n",
    "                missing_cpds[new_cpd]=1\n",
    "                all_matched=False\n",
    "\n",
    "        if(all_matched is False):\n",
    "            print(\"Warning: missing \"+curation_source+\" identifiers for reaction \"+rxn['ID']+\": \"+rxn['EQUATION'])\n",
    "            continue\n",
    "        \n",
    "        rxn_cpds_array = reactions_helper.parseEquation(rxn['EQUATION'])\n",
    "        adjusted=False\n",
    "        new_rxn_cpds_array = reactions_helper.removeCpdRedundancy(rxn_cpds_array)\n",
    "        if(len(new_rxn_cpds_array)!=len(rxn_cpds_array)):\n",
    "            adjusted=True\n",
    "        \n",
    "        rxn_code = reactions_helper.generateCode(new_rxn_cpds_array)\n",
    "        matched_rxn=None        \n",
    "        if(len(new_rxn_cpds_array)==0):\n",
    "            matched_rxn = Empty_Rxn_ID\n",
    "        else:\n",
    "            if(rxn_code in reactions_codes):\n",
    "                matched_rxn = sorted(list(reactions_codes[rxn_code]))[0]\n",
    "\n",
    "        #Because we adjust for water a posterior\n",
    "        #We need to include water when matching codes, in case\n",
    "        if(matched_rxn is None):\n",
    "\n",
    "            #Find statuses that only have water imbalance\n",
    "            new_status = reactions_helper.balanceReaction(new_rxn_cpds_array)\n",
    "            if(new_status == \"MI:H:2/O:1\" or new_status == \"MI:H:-2/O:-1\"):\n",
    "                Water_Adjustment = 1\n",
    "                if(\"-1\" in new_status):\n",
    "                    Water_Adjustment = -1\n",
    "\n",
    "                #Adjust for water\n",
    "                reactions_helper.adjustCompound(new_rxn_cpds_array,\"cpd00001\",float(Water_Adjustment))\n",
    "                rxn_code = reactions_helper.generateCode(new_rxn_cpds_array)\n",
    "                if(rxn_code in reactions_codes):\n",
    "                    matched_rxn = sorted(list(reactions_codes[rxn_code]))[0]\n",
    "\n",
    "        if(matched_rxn is not None):\n",
    "            #Add Names, EC and Alias\n",
    "            #Regardless of match-type, add new names\n",
    "            #NB at this point, names shouldn't match _anything_ already in the database\n",
    "            #Names are saved separately as part of the aliases at the end of the script\n",
    "            for name in rxn['NAMES'].split('|'):\n",
    "                if(name not in All_Names):\n",
    "                    #Possible for there to be no names in biochemistry?\n",
    "                    if(matched_rxn not in Names_Dict):\n",
    "                        Names_Dict[matched_rxn]=list()\n",
    "                    Names_Dict[matched_rxn].append(name)\n",
    "                    All_Names[name]=1\n",
    "                    New_Name_Count[matched_rxn]=1\n",
    "\n",
    "            if('ECS' in rxn):\n",
    "                for ec in rxn['ECS'].split('|'):\n",
    "                    if(ec not in All_ECs):\n",
    "                        #Possible for there to be no ecs in biochemistry?\n",
    "                        if(matched_rxn not in ECs_Dict):\n",
    "                            ECs_Dict[matched_rxn]=list()\n",
    "                        ECs_Dict[matched_rxn].append(ec)\n",
    "                        All_ECs[ec]=1\n",
    "                        New_EC_Count[matched_rxn]=1\n",
    "\n",
    "            #Add ID to aliases if the match is with a different reaction\n",
    "            if(matched_rxn not in original_rxn_alias_dict):\n",
    "                original_rxn_alias_dict[matched_rxn]=dict()\n",
    "            if(matched_rxn in original_rxn_alias_dict and curation_source not in original_rxn_alias_dict[matched_rxn]):\n",
    "                original_rxn_alias_dict[matched_rxn][curation_source]=list()\n",
    "            if(rxn['ID'] not in original_rxn_alias_dict[matched_rxn][curation_source]):\n",
    "                original_rxn_alias_dict[matched_rxn][curation_source].append(rxn['ID'])\n",
    "                New_Alias_Count[matched_rxn]=1\n",
    "\n",
    "            #Update source type\n",
    "            reactions_dict[matched_rxn]['source']=curation_source\n",
    "\n",
    "        else:\n",
    "            \n",
    "            #New Reaction!\n",
    "            #Generate new identifier\n",
    "            identifier_count+=1\n",
    "            new_identifier = 'rxn'+str(identifier_count)\n",
    "\n",
    "            new_rxn = copy.deepcopy(Default_Rxn)\n",
    "            new_rxn['id']=new_identifier\n",
    "\n",
    "            #Add new identifier with curation source as alias\n",
    "            original_rxn_alias_dict[new_rxn['id']]={curation_source:[rxn['ID']]}\n",
    "            New_Alias_Count[new_rxn['id']]=1\n",
    "\n",
    "            #Add new names\n",
    "            #Names are saved separately as part of the aliases at the end of the script\n",
    "            for name in rxn['NAMES'].split('|'):\n",
    "                if(new_rxn['name']=='null'):\n",
    "                    new_rxn['name']=name\n",
    "                    new_rxn['abbreviation']=name\n",
    "\n",
    "                if(name not in All_Names):\n",
    "                    #Possible for there to be no names in biochemistry?\n",
    "                    if(new_rxn['id'] not in Names_Dict):\n",
    "                        Names_Dict[new_rxn['id']]=list()\n",
    "                    Names_Dict[new_rxn['id']].append(name)\n",
    "                    All_Names[name]=1\n",
    "                    New_Name_Count[new_rxn['id']]=1\n",
    "\n",
    "            #If no names at all\n",
    "            if(new_rxn['name']=='null'):\n",
    "                new_rxn['name']=rxn['ID']\n",
    "                new_rxn['abbreviation']=rxn['ID']\n",
    "\n",
    "            #ECs\n",
    "            if('ECS' in rxn):\n",
    "                for ec in rxn['ECS'].split('|'):\n",
    "                    if(ec not in All_ECs):\n",
    "                        #Possible for there to be no ecs in biochemistry?\n",
    "                        if(new_rxn['id'] not in ECs_Dict):\n",
    "                            ECs_Dict[new_rxn['id']]=list()\n",
    "                        ECs_Dict[new_rxn['id']].append(ec)\n",
    "                        All_ECs[ec]=1\n",
    "                        New_EC_Count[new_rxn['id']]=1\n",
    "\n",
    "            #Add source type\n",
    "            new_rxn['source']=curation_source\n",
    "\n",
    "            reactions_dict[new_rxn['id']]=new_rxn\n",
    "            New_Rxn_Count[new_rxn['id']]=1\n",
    "\n",
    "            #Rebuild key fields for reaction using parsed equation\n",
    "            stoichiometry=reactions_helper.buildStoich(new_rxn_cpds_array)\n",
    "            reactions_helper.rebuildReaction(reactions_dict[new_rxn['id']],stoichiometry)\n",
    "\n",
    "            #Finally, because several new reactions may share equations\n",
    "            if(rxn_code not in reactions_codes):\n",
    "                reactions_codes[rxn_code]=dict()\n",
    "            reactions_codes[rxn_code][new_rxn['id']]=1\n",
    "#            print(new_rxn['id'],rxn_code,rxn['ID'])\n",
    "\n",
    "if(len(missing_cpds)>0):\n",
    "    print(\"Missing Compounds: \"+\"|\".join(sorted(missing_cpds)))\n",
    "\n",
    "#Here, for matches, re-write names, ecs and aliases\n",
    "if(len(New_EC_Count)>0):\n",
    "    print(\"Saving additional ECs for \"+str(len(New_EC_Count))+\" reactions\")\n",
    "    reactions_helper.saveECs(ECs_Dict)\n",
    "\n",
    "if(len(New_Name_Count)>0):\n",
    "    print(\"Saving additional names for \"+str(len(New_Name_Count))+\" reactions\")\n",
    "    reactions_helper.saveNames(Names_Dict)\n",
    "\n",
    "if(len(New_Alias_Count)>0):\n",
    "    print(\"Saving additional \"+curation_source+\" aliases for \"+str(len(New_Alias_Count))+\" reactions\")\n",
    "    reactions_helper.saveAliases(original_rxn_alias_dict)\n",
    "\n",
    "if(len(New_Rxn_Count)>0):\n",
    "    print(\"Saving \"+str(len(New_Rxn_Count))+\" new reactions from \"+curation_source)\n",
    "    reactions_helper.saveReactions(reactions_dict)\n",
    "\n",
    "#Scripts to run afterwards\n",
    "#../../Biochemistry/Refresh/Rebalance_Reactions.py (very important)\n",
    "#../../Biochemistry/Refresh/Adjust_Reaction_Protons.py\n",
    "#../../Biochemistry/Refresh/Adjust_Reaction_Water.py\n",
    "#../../Biochemistry/Refresh/Merge_Reactions.py (merges may happen because of water)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
