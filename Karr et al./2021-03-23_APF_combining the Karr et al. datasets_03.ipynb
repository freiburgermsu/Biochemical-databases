{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Karr et al. data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidating the reactions data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reactions JSON file from the WCKB was reformatted and exported as a new JSON file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy\n",
    "\n",
    "reactions = json.load(open('./json_data/reactions.json'))\n",
    "         \n",
    "iteration = 0\n",
    "enzyme_names = []\n",
    "enzyme_data ={}\n",
    "for enzyme in reactions['data']:\n",
    "    #print(enzyme['references'])\n",
    "    if enzyme['name'] not in enzyme_names:\n",
    "        enzyme_names.append(enzyme['name'])\n",
    "        \n",
    "for enzyme in enzyme_names:\n",
    "    references_per_enzyme = []\n",
    "    stoichiometry_per_enzyme = []\n",
    "    temperatures_per_enzyme = []\n",
    "    phs_per_enzyme = []\n",
    "    gibbs_free_energies_per_enzyme = []\n",
    "    keqs_per_enzyme = []\n",
    "    forward_kinetics_per_enzyme = []\n",
    "    backward_kinetics_per_enzyme = []\n",
    "    for entry in reactions['data']: \n",
    "        if entry['name'].lower() == enzyme.lower():\n",
    "            #print(enzyme, '\\n', entry)\n",
    "            if entry['references'] not in references_per_enzyme:\n",
    "                references_per_enzyme.append(entry['references'])\n",
    "            if entry['stoichiometry'] not in stoichiometry_per_enzyme:\n",
    "                stoichiometry_per_enzyme.append(entry['stoichiometry'])\n",
    "            if entry['optimal_temperature'] not in temperatures_per_enzyme:\n",
    "                temperatures_per_enzyme.append(entry['optimal_temperature'])\n",
    "            if entry['delta_g'] not in gibbs_free_energies_per_enzyme:\n",
    "                gibbs_free_energies_per_enzyme.append(entry['delta_g'])\n",
    "            if entry['keq'] not in keqs_per_enzyme:          \n",
    "                keqs_per_enzyme.append(entry['keq'])\n",
    "            if entry['kinetics_forward'] not in forward_kinetics_per_enzyme:\n",
    "                forward_kinetics_per_enzyme.append(entry['kinetics_forward'])\n",
    "            if entry['kinetics_backward'] not in backward_kinetics_per_enzyme:\n",
    "                backward_kinetics_per_enzyme.append(entry['kinetics_backward'])\n",
    "            if entry['optimal_ph'] not in phs_per_enzyme:\n",
    "                phs_per_enzyme.append(entry['optimal_ph'])\n",
    "    \n",
    "        enzyme_data[enzyme] = {'reference':references_per_enzyme,\n",
    "                                  'stoichiometry':stoichiometry_per_enzyme,\n",
    "                                  'optimal temperature':temperatures_per_enzyme,\n",
    "                                  'optimum pH':phs_per_enzyme,\n",
    "                                  'Gibbs free energy':gibbs_free_energies_per_enzyme,\n",
    "                                  'keq':keqs_per_enzyme,\n",
    "                                  'forward kinetics':forward_kinetics_per_enzyme,\n",
    "                                  'backward kinetics':backward_kinetics_per_enzyme}\n",
    "\n",
    "# export the dictionary as a JSON file\n",
    "with open('2021-03-25_APF_WCKB reactions, reorganized.json', 'w') as output:\n",
    "    json.dump(enzyme_data, output, indent = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the references and reactions JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reformatted reactions JSON file from the WCKB is embedded with references. The references were added both to the entire reaction and to the specific forward and backward kinetics data in the respective code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries and JSON files\n",
    "import json\n",
    "import numpy\n",
    "import re\n",
    "\n",
    "reactions = json.load(open('2021-03-25_APF_WCKB reactions, reorganized.json'))\n",
    "references = json.load(open('2021-03-24_APF_Karr et al. references.json'))\n",
    "         \n",
    "    \n",
    "# iteratively insert the references into the corresponding section of the reactions JSON       \n",
    "empty_cells = ['NaN', None, numpy.nan, '', ' ', [], {}]\n",
    "for enzyme, information in reactions.items():\n",
    "    \n",
    "    # loop through the main references\n",
    "    for dict in information['reference']:\n",
    "        #print(id)\n",
    "        new_references_list = []\n",
    "        for reference in dict:\n",
    "            for id, key in references.items(): \n",
    "                #print('list:\\t', list)\n",
    "                #print('reference:\\t',reference, '\\t\\tID:', id)\n",
    "                if reference == id:\n",
    "                    new_references_list.append(key)\n",
    "                    #print('main:\\t', key)\n",
    "                    #print(new_references_list)\n",
    "            \n",
    "        #print(new_references_list)\n",
    "        #print(new_references_list)\n",
    "        information['reference'] = new_references_list\n",
    "        \n",
    "    # loop through the forward kinetics references\n",
    "    for dict in information['forward kinetics']:\n",
    "        #print(list)\n",
    "        if (dict and dict['evidence']) not in empty_cells:\n",
    "            evidence_loop = 0\n",
    "            for reference in dict['evidence']:\n",
    "                new_references_list = []\n",
    "                for key2, value2 in reference.items():\n",
    "                    if key2 == 'references':\n",
    "                        for reference_item in value2:\n",
    "                            #print(reference_item)\n",
    "                            #print('reference:\\t',reference)\n",
    "                            #print('key2:\\t\\t', key2)\n",
    "                            for id, key in references.items(): \n",
    "                                if reference_item == id:\n",
    "                                    new_references_list.append(key)\n",
    "                                    #print('forward:\\t', key)\n",
    "\n",
    "                #print(new_references_list)\n",
    "                #print(list)\n",
    "                dict['evidence'][evidence_loop]['references'] = new_references_list      \n",
    "                evidence_loop += 1\n",
    "\n",
    "    # loop through the backward kinetics references\n",
    "    for dict in information['backward kinetics']:\n",
    "        #print(list)\n",
    "        if (dict and dict['evidence']) not in empty_cells:\n",
    "            evidence_loop = 0\n",
    "            for reference in dict['evidence']:\n",
    "                new_references_list = []\n",
    "                for key2, value2 in reference.items():\n",
    "                    if key2 == 'references':\n",
    "                        for reference_item in value2:\n",
    "                            for id, key in references.items(): \n",
    "                                if reference_item == id:\n",
    "                                    new_references_list.append(key)\n",
    "                                    #print('backward:\\t', key)\n",
    "\n",
    "                #print(new_references_list)\n",
    "                dict['evidence'][evidence_loop]['references'] = new_references_list      \n",
    "                evidence_loop += 1\n",
    "        \n",
    "# export the dictionary as a JSON file\n",
    "with open('2021-03-25_APF_WCKB reactions + references.json', 'w') as output:\n",
    "    json.dump(reactions, output, indent = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrasting the Karr et al. data sources "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reactions from the supplemental excel file and the exported and scraped resources from the WholeCellKB.org were compared. The exported data possessed 27 more kinetically described enzymes than the scraped WholeCellKB.org data. The exported data was equivalent to the scraped data with respect to thermodynamic data. The exported data was therefore concluded to be representative of the WholeCellKB.org database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries and the JSON data files        \n",
    "import pandas\n",
    "import numpy\n",
    "import json\n",
    "import re\n",
    "\n",
    "wckb_scraped = pandas.read_csv('reactions.csv')\n",
    "wckb_json = json.load(open('2021-03-22_APF_WCKB reactions + references.json'))\n",
    "karr_excel_reactions = json.load(open('2021-03-17_APF_Karr et al. kinetic data.json'))\n",
    "empty_cells = ['NaN', None, numpy.nan, '', ' ', [], {}, 'null', 'None']    \n",
    "\n",
    "    \n",
    "    \n",
    "# examine the downloaded reactions from the WholeCellKB.org\n",
    "wckb_json_enzymes = []\n",
    "thermodynamic_reactions = []\n",
    "kinetics_reactions = []\n",
    "for enzyme, value in wckb_json.items():\n",
    "    if enzyme not in wckb_json_enzymes:\n",
    "        #print(enzyme)\n",
    "        wckb_json_enzymes.append(enzyme)\n",
    "        for keq in value['keq']:\n",
    "            if keq not in empty_cells:\n",
    "                thermodynamic_reactions.append(enzyme)\n",
    "        for gibbs in value['Gibbs free energy']:\n",
    "            if gibbs not in empty_cells and enzyme not in thermodynamic_reactions:\n",
    "                thermodynamic_reactions.append(enzyme)\n",
    "        for forward_kinetics in value['forward kinetics']:\n",
    "            if forward_kinetics not in empty_cells:\n",
    "                if enzyme not in kinetics_reactions:\n",
    "                    kinetics_reactions.append(enzyme)\n",
    "        for backward_kinetics in value['backward kinetics']:\n",
    "            if backward_kinetics not in empty_cells:\n",
    "                if enzyme not in kinetics_reactions:\n",
    "                    kinetics_reactions.append(enzyme)\n",
    "thermodynamics_and_kinetics_export = set(thermodynamic_reactions).intersection(set(kinetics_reactions))\n",
    "print('thermodynamics and kinetics:\\t', len(thermodynamics_and_kinetics_export))\n",
    "print('WCKB exported quantity:\\t\\t', len(wckb_json_enzymes))   \n",
    "print('WCKB exported thermodynamic quantity:\\t', len(thermodynamic_reactions))\n",
    "print('WCKB exported kinetic quantity:\\t', len(kinetics_reactions))\n",
    "        \n",
    "        \n",
    "# examine the scraped reactions of the WholeCellKB.org \n",
    "wckb_scraped_enzymes = []\n",
    "thermodynmic_reactions_scraped = []\n",
    "kinetic_reactions_scraped = []\n",
    "for index, row in wckb_scraped.iterrows():\n",
    "    enzyme = wckb_scraped.at[index, 'Name']\n",
    "    if enzyme not in wckb_scraped_enzymes:\n",
    "        #print(enzyme)\n",
    "        wckb_scraped_enzymes.append(enzyme)\n",
    "        if wckb_scraped.at[index, 'deltaG'] not in empty_cells or wckb_scraped.at[index, 'Keq'] not in empty_cells:\n",
    "            if enzyme not in thermodynmic_reactions_scraped:\n",
    "                thermodynmic_reactions_scraped.append(enzyme)\n",
    "        if wckb_scraped.at[index, 'Forward kinetics'] not in empty_cells or wckb_scraped.at[index, 'Backward kinetics'] not in empty_cells:\n",
    "            if enzyme not in kinetic_reactions_scraped:\n",
    "                kinetic_reactions_scraped.append(enzyme)\n",
    "print('WCKB scraped quantity:\\t\\t', len(wckb_scraped_enzymes))   \n",
    "print('WCKB scraped thermodynamic quantity:\\t', len(thermodynmic_reactions_scraped))\n",
    "print('WCKB scraped kinetic quantity:\\t', len(kinetic_reactions_scraped))\n",
    "    \n",
    "    \n",
    "# the thermodynamnically described reactions between the exported data and the scraped data are equivalent\n",
    "thermodynamic_difference_scraped_export = set(thermodynmic_reactions_scraped) - set(thermodynamic_reactions)  \n",
    "thermodynamic_difference_export_scraped = set(thermodynamic_reactions) - set(thermodynmic_reactions_scraped) \n",
    "'''print('thermodynamic_difference_export_scraped:\\t', len(thermodynamic_difference_export_scraped))\n",
    "print('\\nthermodynamic_difference_scraped_export:\\t', len(thermodynamic_difference_scraped_export))\n",
    "for enzyme in thermodynamic_difference_scraped_export:\n",
    "    print(enzyme)\n",
    "for index, row in wckb_scraped.iterrows():\n",
    "    enzyme = wckb_scraped.at[index, 'Name']\n",
    "    if enzyme in thermodynamic_difference_scraped_export:\n",
    "        deltag = wckb_scraped.at[index, 'deltaG']\n",
    "            for enzyme2, value in wckb_json.items():\n",
    "                if enzyme2 == enzyme:\n",
    "                    value['Gibbs free energy'] = deltag\n",
    "'''    \n",
    "    #print(enzyme)\n",
    "\n",
    "    \n",
    "# the kinetically described reactions between the exported data and the scraped data are equivalent\n",
    "kinetic_difference_export_scraped = set(kinetics_reactions) - set(kinetic_reactions_scraped)   \n",
    "kinetic_difference_scraped_export = set(kinetic_reactions_scraped) - set(kinetics_reactions)\n",
    "'''print('\\nkinetic_difference_export_scraped:\\t', len(kinetic_difference_export_scraped))\n",
    "for enzyme in kinetic_difference_export_scraped:\n",
    "    print(enzyme)\n",
    "print('kinetic_difference_scraped_export:\\t', len(kinetic_difference_scraped_export))\n",
    "for enzyme in kinetic_difference_scraped_export:\n",
    "    print(enzyme)'''\n",
    "    \n",
    "\n",
    "# the downloaded and scraped datasets were demonstrated to be identical with the named enzymes   \n",
    "scraped_minus_export = set(wckb_scraped_enzymes) - set(wckb_json_enzymes)\n",
    "export_minus_scraped = set(wckb_json_enzymes) - set(wckb_scraped_enzymes) \n",
    "#print(len(export_minus_scraped - scraped_minus_export))\n",
    "comma_removed_from_export = []\n",
    "for enzyme2 in export_minus_scraped:\n",
    "    #print(enzyme2)\n",
    "    if enzyme2 not in empty_cells:\n",
    "        cleaned_enzyme = re.sub(',','', enzyme2)\n",
    "        comma_removed_from_export.append(enzyme2) \n",
    "        \n",
    "noncomma_differences = scraped_minus_export.intersection(comma_removed_from_export)\n",
    "print('\\nnoncomma_differences:\\t\\t', len(noncomma_differences))\n",
    "\n",
    "comma_removed_duplicates_from_export = []\n",
    "comma_removed_duplicates_from_scraped = []\n",
    "for enzyme in scraped_minus_export:\n",
    "    #print(enzyme)\n",
    "    for enzyme2 in export_minus_scraped:\n",
    "        #print(enzyme) \n",
    "        cleaned_enzyme = re.sub(',','', enzyme2)\n",
    "        if cleaned_enzyme == enzyme:\n",
    "            if enzyme not in comma_removed_duplicates_from_export and enzyme not in export_minus_scraped:\n",
    "                comma_removed_duplicates_from_export.append(enzyme)\n",
    "                #print(enzyme, '\\n', enzyme2, '\\n\\n')\n",
    "    \n",
    "    if enzyme not in empty_cells:\n",
    "        cleaned_enzyme = re.sub(',','', enzyme)\n",
    "        for enzyme2 in export_minus_scraped:\n",
    "            if cleaned_enzyme == enzyme2:\n",
    "                if enzyme2 not in comma_removed_duplicates_from_scraped and enzyme2 not in scraped_minus_export:\n",
    "                    comma_removed_duplicates_from_scraped.append(enzyme2)\n",
    "                    #print(enzyme2, '\\n', enzyme, '\\n\\n')\n",
    "comma_removed_duplicates = set(comma_removed_duplicates_from_scraped).union(set(comma_removed_duplicates_from_export))\n",
    "print('comma_removed_duplicates:\\t',len(comma_removed_duplicates))\n",
    "print('comma_removed_duplicates_from_export:\\t', len(comma_removed_duplicates_from_export))\n",
    "print('comma_removed_duplicates_from_scraped:\\t', len(comma_removed_duplicates_from_scraped))\n",
    "\n",
    "\n",
    "\n",
    "# the excel file dataset was determined to possess identical reaction data as the WholeCellKB datasets\n",
    "all_karr_enzymes = []\n",
    "not_in_json_files = []\n",
    "missing_thermodynamic_enzymes = []\n",
    "missing_kinetic_enzymes = []\n",
    "for enzyme in wckb_json_enzymes:\n",
    "    if enzyme not in all_karr_enzymes:\n",
    "        all_karr_enzymes.append(enzyme)\n",
    "for id2, value2 in karr_excel_reactions.items():  \n",
    "    enzyme2 = re.sub(',', '', value2['Enzyme Name']) \n",
    "    if enzyme2 not in all_karr_enzymes:\n",
    "        print(enzyme2)\n",
    "        not_in_json_files.append(enzyme2)\n",
    "    for enzyme, value in wckb_json.items():\n",
    "        if enzyme == enzyme2:\n",
    "            for forward_kinetics in value['forward kinetics']:\n",
    "                if forward_kinetics not in empty_cells and value2['Forward Km'] not in empty_cells:\n",
    "                    if enzyme not in missing_kinetic_enzymes:\n",
    "                        missing_kinetic_enzymes.append(enzyme)\n",
    "            for backward_kinetics in value['backward kinetics']:\n",
    "                if backward_kinetics not in empty_cells and value2['Backward Km'] not in empty_cells:\n",
    "                    if enzyme not in missing_kinetic_enzymes:\n",
    "                        missing_kinetic_enzymes.append(enzyme)\n",
    "print('not_in_json_files:\\t\\t', len(not_in_json_files))\n",
    "print('missing_kinetic_enzymes:\\t', len(missing_kinetic_enzymes))\n",
    "\n",
    "\n",
    "# the excel file dataset was determined \n",
    "#print('Karr total quantity:\\t', len(karr_excel_reactions_enzymes))   \n",
    "#print('Karr total thermodynamic quantity:\\t', len())\n",
    "#print('Karr total kinetic quantity:\\t', len())\n",
    "\n",
    "#print('Scraped minus export data:\\t', len(scraped_minus_export.union(export_minus_scraped)))\n",
    "#print('\\n\\n\\n\\n')\n",
    "\n",
    "'''for enzyme in scraped_minus_export.union(export_minus_scraped):\n",
    "      print(enzyme)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## format-data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exported JSON files from the WCKB were reformatted and saved as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@authors: Ethan Chan, Matthew Freiburger\n",
    "\"\"\"\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd \n",
    "import json \n",
    "import string #String for removing non-encodable characters\n",
    "\n",
    "# Import scraped data \n",
    "reactions_import = pd.read_json(\"./data/reactions.json\")\n",
    "metabolites_import = pd.read_json(\"./data/metabolites.json\")\n",
    "processes_import = pd.read_json(\"./data/processes.json\")\n",
    "stimuli_import = pd.read_json(\"./data/stimuli.json\")\n",
    "states_import = pd.read_json(\"./data/states.json\")\n",
    "compartments_import = pd.read_json(\"./data/compartments.json\")\n",
    "protein_monomers_import = pd.read_json(\"./data/protein_monomers.json\")\n",
    "protein_complexes_import = pd.read_json(\"./data/protein_complexes.json\")\n",
    "\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "# create the output file\n",
    "reactions_out = open(\"./data/reactions.csv\", \"w\")\n",
    "reactions_out.write(\"\"\"name,enzyme,enzyme_compartment,delta_g,direction,keq,kinetics_backward_rate_law,\n",
    "                        kinetics_forward_rate_law,model,optimal_tempature,pathways,processes,stoichiometry\"\"\")\n",
    "\n",
    "# Loop through all imported reactions\n",
    "for data in reactions_import[\"data\"]:\n",
    "\n",
    "    # transpose the reactions JSON file into a csv file\n",
    "    kinetics_forward_rate_law = \"None\"\n",
    "    if not data[\"forward kinetics\"] == None:\n",
    "        kinetics_forward_rate_law = data[\"forward kinetics\"][\"evidence\"]['value']\n",
    "    kinetics_backward_rate_law = \"None\"\n",
    "    if not data[\"backward kinetics\"] == None:\n",
    "        kinetics_backward_rate_law = data[\"backward kinetics\"][\"evidence\"]['value']\n",
    "    optimal_temperature = \"None\"\n",
    "    if not data[\"optimal_temperature\"] == None:\n",
    "        optimal_temperature = data[\"optimal_temperature\"][\"value\"]\n",
    "    stoichiometry = \"None\"\n",
    "    first = True\n",
    "    for molecule in data[\"stoichiometry\"]:\n",
    "        if first:\n",
    "            stoichiometry = molecule[\"coefficient\"] + \":\" + molecule[\"compartment\"] + \":\" + molecule[\"molecule\"]\n",
    "            first = False\n",
    "        else:\n",
    "            stoichiometry += \";\" + molecule[\"coefficient\"] + \":\" + molecule[\"compartment\"] + \":\" + molecule[\"molecule\"]\n",
    "\n",
    "    pathways_string = \"None\"\n",
    "    if not data[\"pathways\"] == []:\n",
    "        pathways_string = data[\"pathways\"][0]\n",
    "    enzyme_protein_string = \"None\"\n",
    "    enzyme_compartment_string = \"None\"\n",
    "    if not data[\"enzyme\"] == None:\n",
    "        enzyme_protein_string = data[\"enzyme\"][\"protein\"]\n",
    "        enzyme_compartment_string = data[\"enzyme\"][\"compartment\"]\n",
    "        \n",
    "    keq_string = \"None\"\n",
    "    if not data[\"keq\"] == None and not data[\"keq\"][\"value\"] == None:\n",
    "        keq_string = data[\"keq\"][\"value\"]\n",
    "    \n",
    "    type_string = \"None\"\n",
    "    if not data[\"type\"] == None and not data[\"type\"] == []:\n",
    "        if not data[\"type\"][0] == None:\n",
    "            type_string = data[\"type\"][0]\n",
    "\n",
    "    name_string = \"None\"\n",
    "    if not data[\"name\"] == None:\n",
    "        name_string = data[\"name\"]\n",
    "        \n",
    "    delta_g_string = \"None\"\n",
    "    if not data[\"delta_g\"] == None:\n",
    "        delta_g_string = data[\"delta_g\"]\n",
    "    \n",
    "    direction_string = \"None\"\n",
    "    if not data[\"direction\"] == None:\n",
    "        direction_string = data[\"direction\"]\n",
    "        \n",
    "    processes_string = \"None\"\n",
    "    if not data[\"processes\"] == None:\n",
    "        processes_string = data[\"processes\"]\n",
    "        \n",
    "    name_string = name_string.replace(\",\", \"\")\n",
    "    enzyme_compartment_string = enzyme_compartment_string.replace(\",\", \"\")\n",
    "    delta_g_string = delta_g_string.replace(\",\", \"\")\n",
    "    direction_string = direction_string.replace(\",\", \"\")\n",
    "    keq_string = keq_string.replace(\",\", \"\")\n",
    "    kinetics_backward_vmax = kinetics_backward_vmax.replace(\",\", \"\")\n",
    "    \n",
    "    # create and filter the final output string\n",
    "    out_string = str(name_string) + \",\" + str(enzyme_protein_string) + \",\" + str(enzyme_compartment_string) + \",\" + \",\" + str(delta_g_string) + \",\" + \",\" + str(keq_string) + \",\" + str(kinetics_backward_vmax) + \",\" + str(kinetics_forward_vmax) + \",\" + str(model_string) + \",\" + str(optimal_ph) + \",\" + str(optimal_temperature) + \",\" + str(pathways_string) + \",\" + str(processes_string) + \",\" + \",\" + str(stoichiometry)\n",
    "    printable = set(string.printable)\n",
    "    out_string = \"\".join(filter(lambda x: x in printable, out_string))\n",
    "    reactions_out.write(\"\\n\")\n",
    "    reactions_out.write(out_string)\n",
    "    \n",
    "#Close the reactions CSV file\n",
    "reactions_out.close()\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "#Open files to write results to\n",
    "metabolites_out = open(\"./data/molecules.csv\", \"w\")\n",
    "\n",
    "#Write headers to file\n",
    "metabolites_out.write(\"WID,charge,delta_g,pi,logp,logd,\")\n",
    "\n",
    "#Loop through all reactions imported\n",
    "for df in metabolites_import[\"data\"]:\n",
    "    \n",
    "    a = df\n",
    "    \n",
    "    # transpose the metabolites JSON file into a csv file        \n",
    "    out_string = str(df[\"wid\"]) + \",\" + \",\" + str(df[\"charge\"]) + \",\" + \",\" + \",\" + str(df[\"deltag_formation\"]) + \",\" + str(df[\"pi\"]) + \",\" + str(df[\"log_p\"]) + \",\" + str(df[\"log_d\"]) \n",
    "        \n",
    "    # Write out collected data to file\n",
    "    metabolites_out.write(\"\\n\")\n",
    "    metabolites_out.write(out_string)\n",
    "\n",
    "metabolites_out.close()\n",
    "\n",
    "#==========================================================================================================================\n",
    "\n",
    "#Open files to write results to\n",
    "compartments_out = open(\"./data/compartments.csv\", \"w\")\n",
    "\n",
    "#Write headers to file\n",
    "compartments_out.write(\"WID,name,protein_monomers,biomass_compositions\")\n",
    "\n",
    "#Loop through all reactions imported\n",
    "for df in compartments_import[\"data\"]:\n",
    "    \n",
    "    #Handlers for None or unexpected type(s) in fields\n",
    "    wid_string = \"None\"\n",
    "    if not df[\"wid\"] == None:\n",
    "        wid_string = df[\"wid\"]\n",
    "        \n",
    "    name_string = \"None\"\n",
    "    if not df[\"name\"] == None:\n",
    "        name_string = df[\"name\"]\n",
    "        \n",
    "    protein_monomers_string = \"None\"\n",
    "    first = True\n",
    "    for protein in df[\"protein_monomers\"]:\n",
    "        if first:\n",
    "            protein_monomers_string = protein\n",
    "            first = False\n",
    "        else:\n",
    "            protein_monomers_string += \":\" + protein\n",
    "\n",
    "    biomass_compositions_string = \"None\"\n",
    "    first = True\n",
    "    for molecules in df[\"biomass_compositions\"]:\n",
    "        if first:\n",
    "            biomass_compositions_string = molecules[\"concentration\"] + \":\" + molecules[\"compartment\"] + \":\" + molecules[\"metabolites\"]\n",
    "            first = False\n",
    "        else:\n",
    "            biomass_compositions_string += \";\" + molecules[\"concentration\"] + \":\" + molecules[\"compartment\"] + \":\" + molecules[\"metabolites\"]\n",
    "\n",
    "    out_string = str(wid_string) + \",\" + str(name_string) + \",\" + str(protein_monomers_string) + \",\" + str(biomass_compositions_string)\n",
    "        \n",
    "    #Write out collected data to file\n",
    "    compartments_out.write(\"\\n\")\n",
    "    compartments_out.write(out_string)\n",
    "\n",
    "#Close file\n",
    "compartments_out.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
