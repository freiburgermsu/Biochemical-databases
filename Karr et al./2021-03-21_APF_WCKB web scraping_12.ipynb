{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole Cell KB web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Whole Cell KB is an impressive repository of bacterial biochemistry. The website was scraped to acquire data that was unprovided by the download feature of the website. The scraped website information was converted into CSV files that can be readily imported as into Python scripts through Pandas for processing in bacterial models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@authors: Ethan Chan, Matthew Freiburger\n",
    "\"\"\"\n",
    "\n",
    "#Import Statements\n",
    "from bs4 import BeautifulSoup #Website Scraping Library\n",
    "import requests #Pulling webpages\n",
    "import pandas as pd #Dataframes\n",
    "import string #String for removing non-encodable characters\n",
    "import re #Regex\n",
    "\n",
    "#Paths\n",
    "root_url = \"https://www.wholecellkb.org/detail/Mgenitalium/\"\n",
    "output_directory = \"./formatted_data\"\n",
    "\n",
    "#Output paths\n",
    "reactions_out_path = \"/reactions.csv\"\n",
    "metabolites_out_path = \"/metabolites.csv\"\n",
    "genes_out_path = \"/genes.csv\"\n",
    "processes_out_path = \"/processes.csv\"\n",
    "chromosome_features_out_path = \"/chromosome_features.csv\"\n",
    "parameters_out_path = \"/parameters.csv\"\n",
    "protein_complexes_out_path = \"/protein_complexes.csv\"\n",
    "protein_monomers_out_path = \"/protein_monomers.csv\"\n",
    "references_out_path = \"/references.csv\"\n",
    "states_out_path = \"/states.csv\"\n",
    "stimuli_out_path = \"/stimuli.csv\"\n",
    "transcription_units_out_path = \"/transcription_units.csv\"\n",
    "transcriptional_regulation_out_path = \"/transcriptional_regulation.csv\"\n",
    "types_out_path = \"/types.csv\"\n",
    "\n",
    "#JSON file in paths\n",
    "reactions_json_path = \"./data/reactions.json\"\n",
    "compartments_json_path = \"./data/compartments.json\"\n",
    "metabolites_json_path = \"./data/metabolites.json\"\n",
    "\n",
    "#Reading JSON files\n",
    "reactions_import = pd.read_json(reactions_json_path)\n",
    "metabolites_import = pd.read_json(metabolites_json_path)\n",
    "compartments_import = pd.read_json(compartments_json_path)\n",
    "\n",
    "#Dataframes for scraping\n",
    "reactions_scrape = pd.DataFrame(columns=[\"WID\", \"Modification\", \"Name\", \"Cross references\", \"Type\", \"Stoichiometry\", \"Is spontaneous\", \"ΔG\", \"Keq\", \"Pathways\", \"Process\", \"References\", \"Metadata\", \"Created\", \"Last updated\", \"Coenzymes\", \"Optimal pH\", \"Optimal temperature\", \"Enzyme\", \"Forward kinetics\", \"Backward kinetics\", \"Comments\", \"State\"])\n",
    "metabolites_scrape = pd.DataFrame(columns=[\"WID\", \"Name\", \"Traditional name\", \"IUPAC name\", \"Cross references\", \"Type\", \"Empirical formula\", \"Charge\", \"Is hydrophobic\", \"Molecular weight\", \"van der Waals volume\", \"ΔfG\", \"pI\", \"logP\", \"logD\", \"Biomass composition\", \"Reaction participant\", \"Created\", \"Last updated\", \"Media composition\", \"References\", \"Comments\", \"SMILES\", \"pKa\", \"Complex subunit\"])\n",
    "genes_scrape = pd.DataFrame(columns=[\"WID\", \"Name\", \"Cross references\", \"Type\", \"Structure\", \"Sequence\", \"Transcription unit\", \"Empirical formula\", \"Molecular weight\", \"Is essential\", \"Relative expression\", \"Half life\", \"Codons\", \"Amino acid\", \"Extinction coefficient\", \"pI\", \"Comments\", \"References\", \"Created\", \"Last updated\", \"Protein product\", \"Homologs\", \"Symbol\"])\n",
    "processes_scrape = pd.DataFrame(columns=[\"WID\", \"References\", \"Name\", \"Initialization order\", \"Chemical reactions\", \"Complex formation reactions\", \"Parameters\", \"Comments\", \"Created\", \"Last updated\"])\n",
    "chromosome_features_scrape = pd.DataFrame(columns=[\"WID\", \"Name\", \"Type\", \"Structure\", \"Genes\", \"Transcription unit\", \"Created\", \"Last updated\", \"Comments\", \"References\", \"Sequence\"])\n",
    "parameters_scrape = pd.DataFrame(columns=[\"WID\", \"Name\", \"Synonyms\", \"Value\", \"State\", \"References\", \"Created\", \"Last updated\", \"Comments\", \"Molecules\", \"Process\"])\n",
    "protein_complexes_scrape = pd.DataFrame(columns=[\"WID\", \"Name\", \"Cross references\", \"Biosynthesis\", \"No. subunits\", \"DNA footprint\", \"Empirical formula\", \"Molecular weight\", \"Extinction coefficient\", \"Half life\", \"Formation process\", \"Localization\", \"Regulatory rule\", \"Enzyme\", \"Reaction participant\", \"Complex subunit\", \"Parameters\", \"Comments\", \"References\", \"Created\", \"Last updated\"])\n",
    "protein_monomers_scrape = pd.DataFrame(columns=[\"WID\", \"Name\", \"Cross references\", \"Gene\", \"Is N terminal methionine cleaved\", \"Empirical formula\", \"Molecular weight\", \"Extinction coefficient\", \"Instability index\", \"Is stable\", \"Aliphatic index\", \"GRAVY\", \"Half life\", \"Localization\", \"Chaperones\", \"Complex subunit\", \"Comments\", \"References\", \"Created\", \"Last updated\", \"DNA footprint\", \"Enzyme\", \"Reaction participant\", \"Prosthetic groups\", \"Parameters\", \"Sequence\"])\n",
    "references_scrape = pd.DataFrame(columns=[\"WID\", \"Name\", \"Cross references\", \"Type\", \"Citation\", \"Cited by\", \"Created\", \"Last updated\", \"Comments\"])\n",
    "states_scrape = pd.DataFrame(columns=[\"WID\", \"Name\", \"Reactions\", \"Parameters\", \"Created\", \"Last updated\", \"Comments\"])\n",
    "stimuli_scrape = pd.DataFrame(columns=[\"WID\", \"Name\", \"Value\", \"Reaction participant\", \"Comments\", \"References\", \"Created\", \"Last updated\"])\n",
    "transcription_units_scrape = pd.DataFrame(columns=[\"WID\", \"Name\", \"Structure\", \"Genes\", \"Promoter  35 box coordinate (nt)\", \"Promoter  35 box length (nt)\", \"Promoter  10 box coordinate (nt)\", \"Promoter  10 box length (nt)\", \"Transcription start site coordinate (nt)\", \"Created\", \"Last updated\", \"Sequence\", \"Regulation\"])\n",
    "transcriptional_regulation_scrape = pd.DataFrame(columns=[\"WID\", \"Name\", \"Affinity\", \"Transcription unit\", \"Transcripton factor\", \"Binding site\", \"Fold change activity\", \"Comments\", \"References\", \"Created\", \"Last updated\"])\n",
    "types_scrape = pd.DataFrame(columns=[\"WID\", \"Name\", \"Members\", \"Created\", \"Last updated\", \"Children\", \"Parent\"])\n",
    "\n",
    "#URLs for sections\n",
    "reactions_url = \"https://www.wholecellkb.org/list/Mgenitalium/Reaction\"\n",
    "metabolites_url = \"https://www.wholecellkb.org/list/Mgenitalium/Metabolite\"\n",
    "genes_url = \"https://www.wholecellkb.org/list/Mgenitalium/Gene\"\n",
    "processes_url = \"https://www.wholecellkb.org/list/Mgenitalium/Process\"\n",
    "chromosome_features_url = \"https://www.wholecellkb.org/list/Mgenitalium/ChromosomeFeature\"\n",
    "parameters_url = \"https://www.wholecellkb.org/list/Mgenitalium/Parameter\"\n",
    "protein_complexes_url = \"https://www.wholecellkb.org/list/Mgenitalium/ProteinComplex\"\n",
    "protein_monomers_url = \"https://www.wholecellkb.org/list/Mgenitalium/ProteinMonomer\"\n",
    "references_url = \"https://www.wholecellkb.org/list/Mgenitalium/Reference\"\n",
    "states_url = \"https://www.wholecellkb.org/list/Mgenitalium/State\"\n",
    "stimuli_url = \"https://www.wholecellkb.org/list/Mgenitalium/Stimulus\"\n",
    "transcriptional_units_url = \"https://www.wholecellkb.org/list/Mgenitalium/TranscriptionUnit\"\n",
    "transcriptional_regulation_url = \"https://www.wholecellkb.org/list/Mgenitalium/TranscriptionalRegulation\"\n",
    "types_url = \"https://www.wholecellkb.org/list/Mgenitalium/Type\"\n",
    "\n",
    "\n",
    "#====================================================================================================================================\n",
    "#sub-urls for reactions, metabolites, and genes are mined\n",
    "def scrape_sub_urls(url):\n",
    "    \n",
    "    #Items of the url are found in the table on the page\n",
    "    sub_urls = []\n",
    "    \n",
    "    #The sub-urls are appended to a list for return\n",
    "    for row in BeautifulSoup(requests.get(url).text, \"lxml\").find(\"table\", attrs={\"id\": \"list\"}).tbody.find_all(\"tr\"):\n",
    "        for th in row.find_all(\"th\"):\n",
    "            sub_urls.append(th.text)\n",
    "    \n",
    "    return sub_urls\n",
    "    \n",
    "\n",
    "#====================================================================================================================================\n",
    "\n",
    "#specifies whether the argument character is a nucleotide base\n",
    "def is_base(c):\n",
    "    if c == \"A\" or c == \"C\" or c == \"T\" or c == \"G\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "#cleans non-ascii characters, and correlates string to df column\n",
    "def correlate_string(th):\n",
    "    if \"Is\" in th and \"spontaneous\" in th:\n",
    "        return \"Is spontaneous\"\n",
    "    elif \"ΔG\" in th:\n",
    "        th = \"ΔG\"\n",
    "    elif \"ΔfG\" in th:\n",
    "        th = \"ΔfG\"\n",
    "    elif \"logD\" in th:\n",
    "        th = \"logD\"\n",
    "    elif \"Charge\" in th:\n",
    "        th = \"Charge\"\n",
    "    elif \"SMILES\" in th:\n",
    "        th = \"SMILES\"\n",
    "    elif \"Empirical\" in th and \"formula\" in th:\n",
    "        th = \"Empirical formula\"\n",
    "    elif \"Molecular\" in str(th):\n",
    "        th = \"Molecular weight\"\n",
    "    elif \"volume\" in th and \"van\" in th and \"der\" in th and \"Waals\" in th:\n",
    "        th = \"van der Waals volume\"\n",
    "    elif \"Biomass\" in th and \"composition\" in th:\n",
    "        th = \"Biomass composition\"\n",
    "    elif \"Is\" in th and \"hydrophobic\" in th:\n",
    "        th = \"Is hydrophobic\"\n",
    "    elif \"Traditional\" in th and \"name\" in th:\n",
    "        th = \"Traditional name\"\n",
    "    elif \"IUPAC\" in th and \"name\" in th:\n",
    "        th = \"IUPAC name\"\n",
    "    elif \"Cross\" in th and \"references\" in th:\n",
    "        th = \"Cross references\"\n",
    "    elif \"Reaction\" in th and \"participant\" in th:\n",
    "        th = \"Reaction participant\"\n",
    "    elif \"Last\" in th and \"updated\" in th:\n",
    "        th = \"Last updated\"\n",
    "    elif \"Media\" in th and \"composition\" in th:\n",
    "        th = \"Media composition\"\n",
    "    elif \"Complex\" in th and \"subunit\" in th:\n",
    "        th = \"Complex subunit\"\n",
    "    elif \"Optimal\" in th and \"pH\" in th:\n",
    "        th = \"Optimal pH\"\n",
    "    elif \"Optimal\" in th and \"temperature\" in th:\n",
    "        th = \"Optimal temperature\"\n",
    "    elif \"Forward\" in th and \"kinetics\" in th:\n",
    "        th = \"Forward kinetics\"\n",
    "    elif \"Backward\" in th and \"kinetics\" in th:\n",
    "        th = \"Backward kinetics\"\n",
    "    elif \"Transcription\" in th and \"unit\" in th:\n",
    "        th = \"Transcription unit\"\n",
    "    elif \"Is\" in th and \"essential\" in th:\n",
    "        th = \"Is essential\"\n",
    "    elif \"Relative\" in th and \"expression\" in th:\n",
    "        th = \"Relative expression\"\n",
    "    elif \"Half\" in th and \"life\" in th:\n",
    "        th = \"Half life\"\n",
    "    elif \"Amino\" in th and \"acid\" in th:\n",
    "        th = \"Amino acid\"\n",
    "    elif \"Extinction\" in th and \"coefficient\" in th:\n",
    "        th = \"Extinction coefficient\"\n",
    "    elif \"GRAVY\" in th:\n",
    "        th = \"GRAVY\"\n",
    "    else:\n",
    "        th = ''.join(i if ord(i)<128 else ' ' for i in th)\n",
    "\n",
    "    return th\n",
    "    \n",
    "#strips the strings of newlines and spaces\n",
    "def clean_string(s):\n",
    "    return s.strip(\"\\n\").lstrip().rstrip() \n",
    "\n",
    "#scrapes the website and returns results into the dataframe\n",
    "def scrape_section(url, dataframe):\n",
    "    df_index = 0\n",
    " \n",
    "    #scrape each sub-url of section\n",
    "    for sub_url in scrape_sub_urls(url):\n",
    "        \n",
    "        \n",
    "        #scrape and format to get key and value pairs\n",
    "        dataframe.loc[df_index] = len(dataframe.columns) * [None]        \n",
    "        \n",
    "        for tbody in BeautifulSoup(requests.get(root_url + sub_url).text, \"lxml\").find(\"table\", attrs={\"id\": \"detail\"}).find_all(\"tbody\", attrs={\"class\": \"data\"}):\n",
    "\n",
    "            data_rows = tbody.find_all(\"tr\")\n",
    "            \n",
    "            #for every property:value pair extract data\n",
    "            for tr in data_rows:\n",
    "                th = tr.find(\"th\")\n",
    "                td = tr.find(\"td\")\n",
    "                \n",
    "                #existing \"th\" and \"td\" instances are trimmed\n",
    "                if th != None and td != None:\n",
    "                    th = clean_string(th.text)\n",
    "                    td = clean_string(td.text)\n",
    "                    \n",
    "                    #the mined characteristics are purified of non-ascii characters\n",
    "                    th = correlate_string(th)                    \n",
    "                \n",
    "                    if th == \"Sequence\":\n",
    "\n",
    "                        td = re.search(\".*Sequence: [0-9]*\\B([ACTG0-9]*)\", td)\n",
    "                        if td != None:\n",
    "                            td = \"\".join([base for base in td.group(1) if is_base(base)])\n",
    "                        dataframe.loc[df_index][th] = td\n",
    "                    elif th in dataframe:\n",
    "                        dataframe.loc[df_index][th] = td\n",
    "                    elif not th in dataframe:\n",
    "                        print(th)\n",
    "                \n",
    "                    \n",
    "        df_index += 1\n",
    "\n",
    "#scrapes the website and writes results to a csv file\n",
    "def scrape_write(url, dataframe, out_path):\n",
    "    scrape_section(url, dataframe)\n",
    "    dataframe.to_csv(output_directory + out_path, na_rep=\"None\")\n",
    "    \n",
    "#====================================================================================================================================\n",
    "\n",
    "#the reactions, metabolites, and genes sections are scraped and written                        \n",
    "scrape_section(reactions_url, reactions_scrape)\n",
    "scrape_section(metabolites_url, metabolites_scrape)\n",
    "scrape_write(genes_url, genes_scrape, genes_out_path)\n",
    "scrape_write(processes_url, processes_scrape, processes_out_path)\n",
    "scrape_write(chromosome_features_url, chromosome_features_scrape, chromosome_features_out_path)\n",
    "scrape_write(parameters_url, parameters_scrape, parameters_out_path)\n",
    "scrape_write(protein_complexes_url, protein_complexes_scrape, protein_complexes_out_path)\n",
    "scrape_write(protein_monomers_url, protein_monomers_scrape, protein_monomers_out_path)\n",
    "scrape_write(references_url, references_scrape, references_out_path) \n",
    "scrape_write(states_url, states_scrape, states_out_path) \n",
    "scrape_write(stimuli_url, stimuli_scrape, stimuli_out_path) \n",
    "scrape_write(transcriptional_units_url, transcription_units_scrape, transcription_units_out_path) \n",
    "scrape_write(transcriptional_regulation_url, transcriptional_regulation_scrape, transcriptional_regulation_out_path) \n",
    "scrape_write(types_url, types_scrape, types_out_path) \n",
    "\n",
    "#====================================================================================================================================\n",
    "\n",
    "#files with fields from downloaded json files and scraping\n",
    "reactions_out = open(output_directory + \"/reactions.csv\", \"w\")\n",
    "reactions_out.write(\"WID,Modification,Name,Cross references,Type,Stoichiometry,Is spontaneous,deltaG,Keq,Pathways,Process,References,Metadata,Created,Last updated,Coenzymes,Optimal pH,Optimal temperature,Enzyme,Forward kinetics,Backward kinetics,Comments,State\")\n",
    "\n",
    "#all imported reactiosn are iteratively processed\n",
    "index = 0\n",
    "for df in reactions_import[\"data\"]:\n",
    "    \n",
    "    #database parameters are interpreted when the value exists\n",
    "    kinetics_forward_vmax = \"None\"\n",
    "    if df[\"kinetics_forward\"] != None:\n",
    "        kinetics_forward_vmax = df[\"kinetics_forward\"][\"vmax\"]\n",
    "        \n",
    "    kinetics_backward_string = \"None\"\n",
    "    if df[\"kinetics_backward\"] != None:\n",
    "        kinetics_backward_string = df[\"kinetics_backward\"][\"vmax\"]\n",
    "        \n",
    "    optimal_ph_string = \"None\"\n",
    "    if df[\"optimal_ph\"] != None:\n",
    "        optimal_ph_string = df[\"optimal_ph\"][\"value\"]\n",
    "\n",
    "    optimal_temperature_string = \"None\"\n",
    "    if df[\"optimal_temperature\"] != None:\n",
    "        optimal_temperature_string = df[\"optimal_temperature\"][\"value\"]\n",
    "        \n",
    "    stoichiometry_string = \"None\"\n",
    "    first = True\n",
    "    for molecule in df[\"stoichiometry\"]:\n",
    "        if first:\n",
    "            stoichiometry_string = molecule[\"coefficient\"] + \":\" + molecule[\"compartment\"] + \":\" + molecule[\"molecule\"]  #!!! ticket 109\n",
    "            first = False\n",
    "        else:\n",
    "            stoichiometry_string += \";\" + molecule[\"coefficient\"] + \":\" + molecule[\"compartment\"] + \":\" + molecule[\"molecule\"]\n",
    "\n",
    "    #strings are named when in exsistence\n",
    "    pathways_string = \"None\"\n",
    "    if not df[\"pathways\"] == [] and not df[\"pathways\"] == None:\n",
    "        pathways_string = df[\"pathways\"][0]\n",
    "\n",
    "    enzyme_protein_string = \"None\"\n",
    "    enzyme_compartment_string = \"None\"\n",
    "    if not df[\"enzyme\"] == None:\n",
    "        enzyme_protein_string = df[\"enzyme\"][\"protein\"]\n",
    "        enzyme_compartment_string = df[\"enzyme\"][\"compartment\"]\n",
    "\n",
    "    keq_string = \"None\"\n",
    "    if not df[\"keq\"] == None:\n",
    "        if not df[\"keq\"][\"value\"] == None:\n",
    "            keq_string = df[\"keq\"][\"value\"]\n",
    "    \n",
    "    type_string = \"None\"\n",
    "    if not df[\"type\"] == None and not df[\"type\"] == []:\n",
    "        if not df[\"type\"][0] == None:\n",
    "            type_string = df[\"type\"][0]\n",
    "\n",
    "    name_string = df[\"name\"]      \n",
    "    is_spontaneous_string = df[\"is_spontaneous\"]  \n",
    "    delta_g_string = df[\"delta_g\"]\n",
    "    direction_string = df[\"direction\"]  \n",
    "    processes_string = df[\"processes\"]\n",
    "    model_string = df[\"model\"]\n",
    "\n",
    "    #exchanging a comma delimiter with a space delimiter\n",
    "    name_string = name_string.replace(\",\", \"\")\n",
    "    enzyme_protein_string = enzyme_protein_string.replace(\",\", \"\")\n",
    "    enzyme_compartment_string = enzyme_compartment_string.replace(\",\", \"\")\n",
    "    is_spontaneous_string = is_spontaneous_string.replace(\",\", \"\")\n",
    "    delta_g_string = delta_g_string.replace(\",\", \"\")\n",
    "    direction_string = direction_string.replace(\",\", \"\")\n",
    "    keq_string = keq_string.replace(\",\", \"\")\n",
    "    kinetics_backward_string = kinetics_backward_string.replace(\",\", \"\")\n",
    "\n",
    "    #adds a comma delimiter for the complete entries of each row    \n",
    "    scrape_row = reactions_scrape.loc[index]\n",
    "    out_string = str(scrape_row[\"WID\"]) + \",\" + str(scrape_row[\"Modification\"]) + \",\" + str(name_string) + \",\" + str(scrape_row[\"Cross references\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"Type\"]) + \",\" + str(stoichiometry_string) + \",\" + str(is_spontaneous_string) + \",\" + str(scrape_row[\"ΔG\"]) + \",\" + str(keq_string) + \",\" + str(scrape_row[\"Pathways\"]) + \",\" + str(scrape_row[\"Process\"]) + \",\" + str(scrape_row[\"References\"]).replace(\",\" ,\"\") + \",\" + str(scrape_row[\"Metadata\"]).replace(\",\" ,\"\") + \",\" + str(scrape_row[\"Created\"]).replace(\",\" ,\"\") + \",\" + str(scrape_row[\"Last updated\"]).replace(\",\" ,\"\") + \",\" + str(scrape_row[\"Coenzymes\"]).replace(\",\" ,\"\") + \",\" + str(optimal_ph_string) + \",\" + str(optimal_temperature_string) + \",\" + str(enzyme_compartment_string) + \",\" + str(kinetics_forward_vmax) + \",\" + str(kinetics_backward_string) + \",\" + str(scrape_row[\"Comments\"]).replace(\",\" ,\"\") + \",\" + str(scrape_row[\"State\"]).replace(\",\" ,\"\")\n",
    "    printable = set(string.printable)\n",
    "    out_string = \"\".join(filter(lambda x: x in printable, out_string))   #!!! ticket 112\n",
    "        \n",
    "    #the data is placed in an output file\n",
    "    reactions_out.write(\"\\n\")\n",
    "    reactions_out.write(out_string)\n",
    "        \n",
    "    index += 1\n",
    "\n",
    "    \n",
    "reactions_out.close()\n",
    "\n",
    "#====================================================================================================================================\n",
    "\n",
    "metabolites_out = open(output_directory + \"/molecules.csv\", \"w\")\n",
    "metabolites_out.write(\"WID,Name,Traditional name,IUPAC name,Cross references,Type,Empirical formula,Charge,Is hydrophobic,Molecular weight,van der Waals volume,fG,pI,logP,logD,Biomass composition,Reaction participant,Created,Last updated,Media composition,References,Comments,SMILES,pKa,Complex subunit\")\n",
    "\n",
    "index = 0\n",
    "\n",
    "#all existing and imported reactions are iteratively stored as objects\n",
    "for df in metabolites_import[\"data\"]:\n",
    "    \n",
    "    media_composition_string = \"None\"\n",
    "    if not df[\"media_composition\"] == None:\n",
    "        media_composition_string = df[\"media_composition\"][\"concentration\"]\n",
    "    type_string = \"None\"\n",
    "    if df[\"type\"]:\n",
    "        type_string = df[\"type\"][0]\n",
    "    \n",
    "    #the data is printed to the output file\n",
    "    scrape_row = metabolites_scrape.loc[index]       \n",
    "\n",
    "    out_string = str(df[\"wid\"]) + \",\" + str(scrape_row[\"Name\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"Traditional name\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"IUPAC name\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"Cross references\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"Type\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"Empirical formula\"]).replace(\",\", \"\") + \",\" + str(df[\"charge\"]) + \",\" + str(df[\"is_hydrophobic\"]) + \",\" + str(scrape_row[\"Molecular weight\"]).replace(\",\", \"\") + \",\" + str(df[\"volume\"]) + \",\" + str(df[\"deltag_formation\"]) + \",\" + str(df[\"pi\"]) + \",\" + str(df[\"log_p\"]) + \",\" + str(df[\"log_d\"]) + \",\" + str(scrape_row[\"Biomass composition\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"Reaction participant\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"Created\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"Last updated\"]).replace(\",\", \"\") + \",\" + str(media_composition_string) + \",\" + str(scrape_row[\"References\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"SMILES\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"Reaction participant\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"pKa\"]).replace(\",\", \"\") + \",\" + str(scrape_row[\"Complex subunit\"]).replace(\",\", \"\")\n",
    "    printable = set(string.printable)\n",
    "    out_string = \"\".join(filter(lambda x: x in printable, out_string))\n",
    "\n",
    "    metabolites_out.write(\"\\n\")\n",
    "    metabolites_out.write(out_string)\n",
    "        \n",
    "    index += 1\n",
    "\n",
    "metabolites_out.close()\n",
    "\n",
    "#====================================================================================================================================\n",
    "\n",
    "compartments_out = open(output_directory + \"/compartments.csv\", \"w\")\n",
    "compartments_out.write(\"WID,Name,Protein monomers,Biomass compositions\")\n",
    "\n",
    "index = 0\n",
    "\n",
    "#Loop through all reactions imported\n",
    "for df in compartments_import[\"data\"]:   #!!! ticket 113\n",
    "\n",
    "    \n",
    "    wid_string = df[\"wid\"] \n",
    "    name_string = df[\"name\"]\n",
    "        \n",
    "    protein_monomers_string = \"None\"\n",
    "    first = True   #!!! ticket 108\n",
    "    for protein in df[\"protein_monomers\"]:\n",
    "        if first:\n",
    "            protein_monomers_string = protein\n",
    "            first = False\n",
    "        else:\n",
    "            protein_monomers_string += \":\" + protein\n",
    "\n",
    "    biomass_compositions_string = \"None\"\n",
    "    first = True    #!!! ticket 108\n",
    "    for molecules in df[\"biomass_compositions\"]:\n",
    "        if first:\n",
    "            biomass_compositions_string = molecules[\"concentration\"] + \";\" + molecules[\"compartment\"] + \";\" + molecules[\"metabolites\"][0]\n",
    "            first = False\n",
    "        else:\n",
    "            biomass_compositions_string += \";\" + molecules[\"concentration\"] + \";\" + molecules[\"compartment\"] + \";\" + molecules[\"metabolites\"][0]\n",
    "\n",
    "    out_string = str(wid_string) + \",\" + str(name_string) + \",\" + str(protein_monomers_string) + \",\" + str(biomass_compositions_string)\n",
    "        \n",
    "    #the data is written to an output file\n",
    "    compartments_out.write(\"\\n\")\n",
    "    compartments_out.write(out_string)\n",
    "\n",
    "compartments_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
