{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIST Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code documents the methods of combining and organizing the scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web scraping was conducted through the following code. Increments of 27 reference ID URLs were scraped to maintain accuracy of the scraper while executing a timely web scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Statements\n",
    "from bs4 import BeautifulSoup\n",
    "import requests #Pulling webpages\n",
    "import pandas \n",
    "import numpy\n",
    "import re\n",
    "import math\n",
    "\n",
    "#defining the website\n",
    "root_url = \"https://randr.nist.gov/enzyme/DataDetails.aspx?ID=\"\n",
    "end_url = \"&finalterm=&data=enzyme\"\n",
    "#===========================================================================================================================\n",
    "\n",
    "#identify the table and rows of pertinent data\n",
    "bs = BeautifulSoup(open('Enzyme Thermodynamic Database.html'), 'lxml')\n",
    "table = bs.find(\"table\", attrs = {'id': 'MainBody_gvSearch'})\n",
    "body = table.find_all(\"tr\")\n",
    "#print(body[1])\n",
    "\n",
    "#defining the initial boundaries of the aggregate dataframe\n",
    "index_range = 12000\n",
    "index_count = 0\n",
    "loop_count = 0 \n",
    "lower_bound = 1 #math.floor(1*len(body)/50)\n",
    "upper_bound = math.floor(1*len(body)/50)\n",
    "\n",
    "#loop through the enzyme id values \n",
    "id_values = []\n",
    "id_refined = ''\n",
    "\n",
    "for row in range(lower_bound,upper_bound):   #\n",
    "    id_value = body[row].find(\"a\")\n",
    "    \n",
    "    #refining the reference IDs \n",
    "    id_refined = re.findall(r\"(\\d+\\w+.\\w+.\\d+)(?<=)\",str(id_value))\n",
    "    scraped_id = str(id_refined).strip('[]')\n",
    "    scraped_id2 = re.sub(r'(\\')', '', scraped_id)\n",
    "    total_url = root_url + scraped_id2 + end_url\n",
    "    \n",
    "    #defining the soup\n",
    "    soup = requests.get(total_url).text\n",
    "    bs = BeautifulSoup(soup, 'lxml')\n",
    "    \n",
    "    #identify the table1, body1, and headers\n",
    "    tables1 = bs.find_all(\"table\", attrs = {\"id\": \"MainBody_extraData\"})\n",
    "    print(scraped_id2, '\\t: ', loop_count, '\\t, ', len(tables1))\n",
    "    if len(tables1) != 1:\n",
    "        continue\n",
    "\n",
    "    body1 = tables1[0].find_all(\"tr\")\n",
    "    body_rows1 = body1[1:]\n",
    "    heads = body1[0]\n",
    "\n",
    "    headings = []\n",
    "    for head in heads.find_all(\"th\"):\n",
    "        head = (head.text).rstrip(\"\\n\")\n",
    "        headings.append(head)\n",
    "\n",
    "\n",
    "    #identify entries of the body rows\n",
    "    total_rows = []\n",
    "    for row_number in range(len(body_rows1)):\n",
    "        each_row = []\n",
    "        for row_element in body_rows1[row_number].find_all(\"td\"):\n",
    "            row_refined = re.sub(\"(\\xa0)|(\\n)|,\",\"\",row_element.text)\n",
    "            each_row.append(row_refined)\n",
    "        total_rows.append(each_row)\n",
    "    \n",
    "    #create a dataframe\n",
    "    index_list_body = range(index_count+lower_bound-1, len(body_rows1)+index_count+lower_bound-1)\n",
    "    bs_dataframe_table1 = pandas.DataFrame(data = total_rows, columns = headings, index = index_list_body)\n",
    "    bs_dataframe_table1.drop(bs_dataframe_table1.columns[len(bs_dataframe_table1.columns)-1], axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "#===========================================================================================================================\n",
    "\n",
    "    #identify table2 and body2\n",
    "    tables = bs.find_all(\"table\", attrs={\"id\": \"MainBody_DataList1\"})\n",
    "    if len(tables) == 0:\n",
    "        continue\n",
    "    body2 = tables[0].find_all(\"tr\")\n",
    "    body_rows2 = body2[1:]\n",
    "\n",
    "    each_row2 = []\n",
    "    for row in range(len(body_rows2)):\n",
    "        for row_element in body_rows2[row].find_all(\"td\"):\n",
    "            row_refined2 = re.sub(\"(\\xa0)|(\\n)|,\",\"\",row_element.text)\n",
    "            each_row2.append(row_refined2)\n",
    "\n",
    "    information_entries_list = []\n",
    "    information_values_list = []\n",
    "    column_count = 0\n",
    "    for i, element in enumerate(each_row2):\n",
    "        if i == 0 or i % 2 == 0:\n",
    "            information_entries_list.append(element)\n",
    "            column_count += 1\n",
    "        else:\n",
    "            information_values_list.append(element)\n",
    "            column_count += 1\n",
    "    column_count /= 2\n",
    "\n",
    "\n",
    "    #create a dataframe\n",
    "    index_list_reference = range(index_count+lower_bound-1, index_count+1+lower_bound-1)\n",
    "    bs_dataframe_pretable2 = pandas.DataFrame(data = [information_values_list], columns = information_entries_list, index = index_list_reference)\n",
    "    bs_dataframe_pretable2.drop(bs_dataframe_pretable2.columns[len(bs_dataframe_pretable2.columns)-2], axis=1, inplace=True)\n",
    "    \n",
    "#===========================================================================================================================\n",
    "\n",
    "    #merge the dataframes of this loop\n",
    "    this_dataframe = bs_dataframe_table1.join(bs_dataframe_pretable2)\n",
    "    this_dataframe.index.name = 'index'\n",
    "    \n",
    "   #iteratively coalesce the new dataframe into the old dataframe \n",
    "    if loop_count == 0:\n",
    "        old_dataframe = this_dataframe\n",
    "        old_dataframe.index.name = 'index'\n",
    "        \n",
    "    elif loop_count > 0:\n",
    "        these_columns = []\n",
    "        for column in this_dataframe:\n",
    "            these_columns.append(column)\n",
    "            \n",
    "        old_columns = []\n",
    "        for existing_column in old_dataframe:\n",
    "            old_columns.append(existing_column)\n",
    "            \n",
    "        common_columns = list(set(these_columns).intersection(old_columns))\n",
    "        \n",
    "        #amalgamate the dataframe with the pre-existing dataframe\n",
    "        current_dataframe = old_dataframe.merge(this_dataframe, on = common_columns, how = 'outer')\n",
    "        old_dataframe = current_dataframe  \n",
    "        \n",
    "\n",
    "    #amalgamate the dataframe with the pre-existing dataframe\n",
    "    index_count += len(body_rows1)\n",
    "    loop_count += 1 \n",
    "\n",
    "\n",
    "#export total_df to csv \n",
    "old_dataframe.to_csv(\"1.csv\")\n",
    "\n",
    "#print(bs_dataframe_table1)\n",
    "old_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV data combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code was combined the individual CSV files. The code was dynamically applied to aggregate CSV files into the segments 1-5, 6-16, 17-36, and 37-50. The code subsequently combined each of the four segments into the complete csv file. The columns were reorganized according to subjective preference with the reference information on the left and the data on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "import re \n",
    "\n",
    "#dataframes definition\n",
    "df1 = pandas.read_csv(\"1-5.csv\", encoding='cp1252')\n",
    "df2 = pandas.read_csv(\"6-16.csv\", encoding='cp1252')\n",
    "df3 = pandas.read_csv(\"17-36.csv\", encoding='cp1252')\n",
    "df4 = pandas.read_csv(\"37-50.csv\", encoding='cp1252')\n",
    "\n",
    "#creating the dataframe\n",
    "dataframes = [df1,df2,df3,df4]\n",
    "combined_csv = pandas.concat([f for f in dataframes])\n",
    "\n",
    "#defining the columns \n",
    "loop_count = 0\n",
    "these_columns = []\n",
    "old_columns = []   \n",
    "total_columns = []\n",
    "\n",
    "for df in dataframes:  \n",
    "    for this_column in df:\n",
    "        if this_column not in total_columns:\n",
    "            total_columns.append(this_column)\n",
    "       \n",
    "right_dataframe_columns = []\n",
    "left_dataframe_columns = [] \n",
    "for column in total_columns:\n",
    "    if re.match(\"(\\w+)(?=:)\", column) or re.match(\"(\\w+\\s\\w+)(?=:)\", column):\n",
    "        if column not in left_dataframe_columns:\n",
    "            left_dataframe_columns.append(column)    \n",
    "            \n",
    "    if column == 'T(K)':\n",
    "        right_dataframe_columns.append(column)\n",
    "    if column == 'pH ':\n",
    "        right_dataframe_columns.append(column)\n",
    "    if column == 'K<sub>c</sub>\\' ':\n",
    "        right_dataframe_columns.append(column)\n",
    "    if column == 'δ<sub>r</sub>H\\'<sup>o</sup>(kJ.mol<sup>-1</sup>)':\n",
    "        right_dataframe_columns.append(column)\n",
    "      \n",
    "defined_columns = left_dataframe_columns + right_dataframe_columns \n",
    "remaining_columns = list(set(defined_columns).symmetric_difference(set(total_columns)))\n",
    "\n",
    "#reorganizing the dataframe\n",
    "final_dataframe_columns = defined_columns + remaining_columns\n",
    "final_dataframe = combined_csv.reindex(columns = final_dataframe_columns)\n",
    "\n",
    "#export total_df to csv \n",
    "final_dataframe.to_csv(\"2021-02-15_APF_vetted complete NIST database 1-50.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code combined columns with akin data in the complete CSV. Suffixes were used to further specify data in columns that combined myriad data sources. The columns were finally renamed with generic conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import re\n",
    "\n",
    "\n",
    "#dataframes definition\n",
    "df = pandas.read_csv(\"2021-02-15_APF_vetted complete NIST database 1-50.csv\")\n",
    "df = df.astype(str)\n",
    "\n",
    "empty_cell = ['nan', 'NaN', 'none', 'not given', '0', '', None]\n",
    "\n",
    "combined_columns = []\n",
    "\n",
    "for this_column in df:\n",
    "    for index, row in df.iterrows():       \n",
    "        \n",
    "        #combine the equilibrium constant columns\n",
    "        if re.search('(?i)(^K)', this_column) and not re.search('(Km\\')', this_column):\n",
    "            if str(df.at[index, this_column]) not in empty_cell: \n",
    "                if str(df.at[index, 'K<sub>c</sub>\\' ']) in empty_cell:\n",
    "                    df.at[index, 'K<sub>c</sub>\\' '] = str(df.at[index, this_column])\n",
    "\n",
    "                if str(df.at[index, this_column]) not in empty_cell:\n",
    "                    if str(df.at[index, 'K<sub>c</sub>\\' ']) != str(df.at[index, this_column]):\n",
    "                        df.at[index, 'K<sub>c</sub>\\' '] = str(df.at[index, 'K<sub>c</sub>\\' ']) + ' & ' + str(df.at[index, this_column])\n",
    "\n",
    "            if this_column !=  'K<sub>c</sub>\\' ':\n",
    "                if this_column not in combined_columns:\n",
    "                    combined_columns.append(this_column)\n",
    "\n",
    "\n",
    "        #combine the ethalpy columns\n",
    "        if re.search('ë«', this_column):\n",
    "            if str(df.at[index, this_column]) not in empty_cell:\n",
    "                if str(df.at[index, 'ë«<sub>r</sub>H(kJ.mol<sup>-1</sup>)']) in empty_cell:\n",
    "                    df.at[index, 'ë«<sub>r</sub>H(kJ.mol<sup>-1</sup>)'] = str(df.at[index, this_column])\n",
    "\n",
    "                if str(df.at[index, this_column]) not in empty_cell:\n",
    "                    if str(df.at[index, 'ë«<sub>r</sub>H(kJ.mol<sup>-1</sup>)']) != str(df.at[index, this_column]):\n",
    "                        df.at[index, 'ë«<sub>r</sub>H(kJ.mol<sup>-1</sup>)'] = str(df.at[index, 'ë«<sub>r</sub>H(kJ.mol<sup>-1</sup>)']) + ' & ' + str(df.at[index, this_column])\n",
    "\n",
    "            if this_column !=  'ë«<sub>r</sub>H(kJ.mol<sup>-1</sup>)':\n",
    "                if this_column not in combined_columns:\n",
    "                    combined_columns.append(this_column)\n",
    "\n",
    "\n",
    "        #combine the concentration ionic strenth columns \n",
    "        if re.search('I<sub>c', this_column): \n",
    "            if str(df.at[index, this_column]) not in empty_cell:\n",
    "                if str(df.at[index, 'I<sub>c</sub>(mol dm<sup>-3</sup>)']) in empty_cell:\n",
    "                    df.at[index, 'I<sub>c</sub>(mol dm<sup>-3</sup>)'] = str(df.at[index, this_column])\n",
    "\n",
    "                if str(df.at[index, this_column]) not in empty_cell:\n",
    "                    if str(df.at[index, 'I<sub>c</sub>(mol dm<sup>-3</sup>)']) != str(df.at[index, this_column]):\n",
    "                        df.at[index, 'I<sub>c</sub>(mol dm<sup>-3</sup>)'] = str(df.at[index, 'δ<sub>r</sub>H\\'<sup>o</sup>(kJ.mol<sup>-1</sup>)']) + ' & ' + str(df.at[index, this_column])\n",
    "\n",
    "            if this_column !=  'I<sub>c</sub>(mol dm<sup>-3</sup>)':\n",
    "                if this_column not in combined_columns:\n",
    "                    combined_columns.append(this_column)\n",
    "\n",
    "\n",
    "        #combine the solute molar concentrations\n",
    "        if re.search('(?<=c\\()(\\w+\\d?\\+?)(?<!,)', this_column):\n",
    "            if re.search('(?<=c\\()(\\w+\\d?\\+?)(?<!,)', this_column):\n",
    "                solute = str(re.search('(?<=c\\()(\\w+\\d?\\+?)(?<!,)', this_column).group(1))\n",
    "                \n",
    "            if str(df.at[index, this_column]) not in empty_cell:\n",
    "                if str(df.at[index, 'c(glycerol,mol dm<sup>-3</sup>)']) in empty_cell:\n",
    "                    df.at[index, 'c(glycerol,mol dm<sup>-3</sup>)'] = str(df.at[index, this_column]) + ' ' + solute\n",
    "\n",
    "                if str(df.at[index, this_column]) not in empty_cell:\n",
    "                    if str(df.at[index, 'c(glycerol,mol dm<sup>-3</sup>)']) != (str(df.at[index, this_column]) or str(df.at[index, this_column]) + ' ' + solute):\n",
    "                        df.at[index, 'c(glycerol,mol dm<sup>-3</sup>)'] = str(df.at[index, 'c(glycerol,mol dm<sup>-3</sup>)']) + ' & ' + str(df.at[index, this_column]) + ' ' + solute\n",
    "\n",
    "            if this_column !=  'c(glycerol,mol dm<sup>-3</sup>)':\n",
    "                if this_column not in combined_columns:\n",
    "                    combined_columns.append(this_column)\n",
    "\n",
    "\n",
    "        #combine the solute molality concentrations\n",
    "        if re.search('(?<=m\\()(\\w+\\d?\\+?)(?<!,)', this_column):\n",
    "            if re.search('(?<=c\\()(\\w+\\d?\\+?)(?<!,)', this_column):\n",
    "                solute = str(re.search('(?<=c\\()(\\w+\\d?\\+?)(?<!,)', this_column).group(1))\n",
    "                \n",
    "            if str(df.at[index, this_column]) not in empty_cell:\n",
    "                if str(df.at[index, 'm(MgCl2,mol.kg<sup>-1</sup>)']) in empty_cell:\n",
    "                    df.at[index, 'm(MgCl2,mol.kg<sup>-1</sup>)'] = str(df.at[index, this_column]) + ' ' + solute\n",
    "\n",
    "                if str(df.at[index, this_column]) not in empty_cell:\n",
    "                    if str(df.at[index, 'm(MgCl2,mol.kg<sup>-1</sup>)']) != (str(df.at[index, this_column]) or str(df.at[index, this_column]) + ' ' + solute):\n",
    "                        df.at[index, 'm(MgCl2,mol.kg<sup>-1</sup>)'] = str(df.at[index, 'm(MgCl2,mol.kg<sup>-1</sup>)']) + ' & ' + str(df.at[index, this_column]) + ' ' + solute\n",
    "\n",
    "            if this_column !=  'm(MgCl2,mol.kg<sup>-1</sup>)':\n",
    "                if this_column not in combined_columns:\n",
    "                    combined_columns.append(this_column)\n",
    "\n",
    "\n",
    "        #combine buffer and solution details\n",
    "        buffer_columns = ['buffer(mol dm<sup>-3</sup>)', 'buffer and/or salt ', 'media ', 'buffer ']\n",
    "        if this_column in buffer_columns:\n",
    "            if str(df.at[index, this_column]) not in empty_cell:\n",
    "                if str(df.at[index, 'Buffer:']) in empty_cell:\n",
    "                    df.at[index, 'Buffer:'] = str(df.at[index, this_column])\n",
    "\n",
    "                if str(df.at[index, 'Buffer:']) not in empty_cell:\n",
    "                    if not re.search(re.escape(str(df.at[index, this_column])), str(df.at[index, 'Buffer:'])):\n",
    "                        df.at[index, 'Buffer:'] = str(df.at[index, 'Buffer:']) + '  +  ' + str(df.at[index, this_column])\n",
    "                        #print('Buffer: ERROR, index: ', index)             \n",
    "\n",
    "            if this_column !=  'Buffer:':\n",
    "                if this_column not in combined_columns:\n",
    "                    combined_columns.append(this_column)\n",
    "\n",
    "        #combine environmental conditions\n",
    "        solution_columns = ['salt ', 'cosolvent ', 'added solute ', 'protein ', 'added solute ', 'percent(dimethyl sulfoxide) ', 'p(MPa)', 'pMg ']\n",
    "        if this_column in solution_columns:\n",
    "            if str(df.at[index, this_column]) not in empty_cell:\n",
    "                if str(df.at[index, 'solvent ']) in empty_cell:\n",
    "                    if str(this_column) == 'p(MPa)':\n",
    "                        #print(\"yes: \", index)\n",
    "                        df.at[index, 'solvent '] = str(df.at[index, this_column]) + ' megapascals'  \n",
    "\n",
    "                    elif str(this_column) == 'pMg ':\n",
    "                        #print('yes: ', index)\n",
    "                        df.at[index, 'solvent '] = str(df.at[index, this_column]) + ' = -log[Mg+2]'   \n",
    "                        \n",
    "                    elif str(this_column) == 'percent(dimethyl sulfoxide) ':\n",
    "                        df.at[index, 'solvent '] = str(df.at[index, this_column]) + ' % DMSO'   \n",
    "\n",
    "                    else:\n",
    "                        df.at[index, 'solvent '] = str(df.at[index, this_column])\n",
    "\n",
    "                if str(df.at[index, 'solvent ']) not in empty_cell:\n",
    "                    if not re.search(re.escape(str(df.at[index, this_column])), str(df.at[index, 'solvent '])):\n",
    "                        df.at[index, 'solvent '] = str(df.at[index, 'solvent ']) + '  +  ' + str(df.at[index, this_column])\n",
    "\n",
    "            if this_column !=  'solvent ':\n",
    "                if this_column not in combined_columns:\n",
    "                    combined_columns.append(this_column)\n",
    "       \n",
    "            \n",
    "#rename the base columns\n",
    "df.rename(columns = {'c(glycerol,mol dm<sup>-3</sup>)':'solutes [mol / dm^3]', \n",
    "                     'I<sub>c</sub>(mol dm<sup>-3</sup>)':'Ionic strength [mol / dm^3]', \n",
    "                     'T(K)':'T [K]', \n",
    "                     'I<sub>m</sub>(mol.kg<sup>-1</sup>)':'Ionic strength [mol / kg]', \n",
    "                     'm(MgCl2,mol.kg<sup>-1</sup>)':'solutes [mol / kg]', \n",
    "                     'solvent ':'Experimental conditions', \n",
    "                     'K<sub>c</sub>\\' ':'Keq', \n",
    "                     'ë«<sub>r</sub>H(kJ.mol<sup>-1</sup>)':'Enthalpy [kJ / mol]'},\n",
    "          inplace = True)\n",
    "            \n",
    "for column in combined_columns:\n",
    "    print(column)\n",
    "    del df[column]\n",
    "    \n",
    "#export total_df to csv \n",
    "df.to_csv(\"2021-03-18_APF_vetted and reorganized complete NIST enzyme database_001.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enzyme names and reactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The enzyme names and corresponding reactions from each reference are added in an adjacent column. The generated file is the final file of the NIST web scraped database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Statements\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas \n",
    "import numpy\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "#import the csv file\n",
    "total_csv = pandas.read_csv(\"2021-03-18_APF_vetted and reorganized complete NIST enzyme database_001.csv\")\n",
    "\n",
    "\n",
    "#import the html file\n",
    "bs = BeautifulSoup(open('Enzyme Thermodynamic Database.html'), 'lxml')\n",
    "#print(bs.prettify())\n",
    "\n",
    "\n",
    "#identify the table and rows of pertinent data\n",
    "table = bs.find(\"table\", attrs = {'id': 'MainBody_gvSearch'})\n",
    "body = table.find_all(\"tr\")\n",
    "#print(body[1])\n",
    "\n",
    "\n",
    "#loop through the enzyme id values \n",
    "reference_ids = []\n",
    "enzyme_names = []\n",
    "reactions = []\n",
    "name_iteration = 0\n",
    "id_refined = ''\n",
    "for row in range(1, len(body)):\n",
    "    id_value = body[row].find(\"a\")\n",
    "    id_refined = re.findall(r\"(\\d+\\w+.\\w+.\\d+)(?<=)\",str(id_value))\n",
    "    reference_ids.append(id_refined)   \n",
    "    \n",
    "    enzyme_name = body[row].find('span', attrs = {'id': 'MainBody_gvSearch_lblEnzyme_%s' %(name_iteration)}).text\n",
    "    enzyme_names.append(enzyme_name)\n",
    "    \n",
    "    reaction = body[row].find('span', attrs = {'id': 'MainBody_gvSearch_lblReaction_%s' %(name_iteration)}).text\n",
    "    reactions.append(reaction)\n",
    "    \n",
    "    name_iteration += 1\n",
    "\n",
    "\n",
    "#create the columns of enzyme names and reactions  \n",
    "enzyme_iteration = 0    \n",
    "empty_cell = ['nan', 'NaN', 'none', 'not given', '0', '', None, numpy.nan]\n",
    "enzyme_column = []\n",
    "reaction_column = []\n",
    "for index, row in total_csv.iterrows():\n",
    "    if total_csv.at[index, 'Reference ID:'] in empty_cell:\n",
    "        enzyme_column.append('nan')\n",
    "        reaction_column.append('nan')\n",
    "        print('yes')\n",
    "    \n",
    "    if total_csv.at[index, 'Reference ID:'] not in empty_cell:\n",
    "        if enzyme_iteration == 1432:\n",
    "            break \n",
    "        print(enzyme_iteration)\n",
    "        enzyme_column.append(enzyme_names[enzyme_iteration])\n",
    "        reaction_column.append(reactions[enzyme_iteration])    \n",
    "        \n",
    "        enzyme_iteration += 1\n",
    "\n",
    "#add the enzyme names and reactions to the CSV file\n",
    "total_csv.insert(1, 'Enzyme', enzyme_column)\n",
    "total_csv.insert(2, 'Reaction', reaction_column)\n",
    "\n",
    "\n",
    "#generating the final CSV file\n",
    "file_number = '1'\n",
    "if not os.path.exists(\"%s_vetted + reorganized NIST_%s.csv\" %(datetime.date.today(), file_number)):\n",
    "    total_csv.to_csv(\"%s_vetted + reorganized NIST_%s.csv\" %(datetime.date.today(), file_number))\n",
    "elif os.path.exists('%s _PHREEQC input file_%s.txt' %(datetime.date.today(), file_number)):\n",
    "    while os.path.exists('%s _PHREEQC input file_%s.txt' %(datetime.date.today(), file_number)):\n",
    "        file_number += 1\n",
    "    total_csv.to_csv(\"%s_vetted + reorganized NIST_%s.csv\" %(datetime.date.today(), file_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
